{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MindSpore2.3动态图模型迁移培训\n",
    "\n",
    "推荐大家用mint\n",
    "\n",
    "mint接口 > ops接口 > nn接口\n",
    "\n",
    "```python\n",
    "mindspore.nn.Cell < torch.nn.Module\n",
    "```\n",
    "\n",
    "解决方案：\n",
    "1. 使用MindTorch\n",
    "2. 使用MindNLP包\n",
    "\n",
    "差异点：\n",
    "```python\n",
    "Tensor.transpose -> Tensor.swapaxes\n",
    "Tensor.expand 不要用 -> broadcast_to\n",
    "dim => axis\n",
    "keepdim => keepdims\n",
    "```\n",
    "\n",
    "### MindTorch -> PyTorch\n",
    "\n",
    "### MindNLP -> Transformers\n",
    "\n",
    "- 不支持静态图\n",
    "- 接口不全\n",
    "\n",
    "### 动态图profile\n",
    "\n",
    "chrom:tracing 打开json文件, 分析运行时间\n",
    "\n",
    "- 绑核\n",
    "  `lsp\n",
    "  `taskset -p -c 0-35 python xxx.py`\n",
    "\n",
    "- 除去Cell\n",
    "  1. 选择使用MindNLP\n",
    "  2. 等2.3版本发布\n",
    "   \n",
    "- 使用mint替换\n",
    "  傻子都会\n",
    "\n",
    "\n",
    "- rms_norm换大算子\n",
    "  1. 有大算子一定用大算子\n",
    "\n",
    "- 精度对齐\n",
    "  1. np.allclose\n",
    "  2. 推理结果\n",
    "  3. 精度对齐思路 : 逐层检查allclose, do_sample=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.mint as mint\n",
    "import mindspore.nn as nn\n",
    "\n",
    "# 初识化\n",
    "def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, has_bias=False):\n",
    "    pass\n",
    "\n",
    "# 前向传播\n",
    "def construct(self, x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 旋转位置编码\n",
    "def apply_rotary_position_embedding(x, freqs, max_seq_len):\n",
    "    seq_len = x.shape[1]\n",
    "    freqs = freqs[:, None]\n",
    "    inv_freq = 1. / (10000 ** (freqs / max_seq_len))\n",
    "    pos_emb = torch.arange(seq_len, dtype=torch.float32, device=x.device)\n",
    "    pos_emb = pos_emb[None, :] * inv_freq\n",
    "    pos_emb = torch.cat((torch.sin(pos_emb), torch.cos(pos_emb)), dim=-1)\n",
    "    pos_emb = pos_emb.unsqueeze(0).repeat(x.shape[0], 1, 1)\n",
    "    return x + pos_emb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MindFormers大模型使能套件\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
