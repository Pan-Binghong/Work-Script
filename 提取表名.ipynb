{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取xlsx文件\n",
    "df = pd.read_excel('原始数据表.xlsx')\n",
    "\n",
    "# 创建新列并复制“SQL查询语句”列的内容\n",
    "df['备份SQL查询语句'] = df['SQL查询语句']\n",
    "\n",
    "# 将结果保存回原来的xlsx文件中\n",
    "df.to_excel('原始数据表.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wseq_tqxs_fyyxs_400V', 'o_org']\n",
      "数据表名称: wseq_tqxs_fyyxs_400V\n",
      "数据表名称: o_org\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# SQL查询语句\n",
    "sql = \"select id as 编号,rq as 日期,gldw as 供电所名称,xsl as 线损率 from wseq_tqxs_fyyxs_400V where rq BETWEEN '2023-01' AND '2023-12' and gldw in (select org_name from o_org where org_no LIKE '134051504%') limit 100\"\n",
    "\n",
    "# 正则表达式\n",
    "pattern = r'from\\s+(\\w+)|join\\s+(\\w+)'\n",
    "\n",
    "# 使用正则表达式提取表名\n",
    "table_names = re.findall(pattern, sql)\n",
    "\n",
    "# 提取出的表名可能包含空元素，需要去除\n",
    "table_names = [name for sublist in table_names for name in sublist if name]\n",
    "\n",
    "print(table_names)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# sql = \"SELECT count(1) FROM buf_pms_scyw.t_sb_znyc_dlq where whbz in (SELECT isc_id from buf_pms_scyw.isc_specialorg_unit_locext locext where isc_id IN ('13B9B47F22E23324E05338297A0A0595','13B9B47F22E33324E05338297A0A0595') or sjbmid IN ('13B9B47F22E23324E05338297A0A0595','13B9B47F22E33324E05338297A0A0595') or ssywdwid IN ('13B9B47F22E23324E05338297A0A0595','13B9B47F22E33324E05338297A0A0595') or ssdsid IN ('13B9B47F22E23324E05338297A0A0595','13B9B47F22E33324E05338297A0A0595') or sswsid IN ('13B9B47F22E23324E05338297A0A0595','13B9B47F22E33324E05338297A0A0595')) and tyrq BETWEEN '2023-01-01' AND '2023-12-31' and yxzt = '20' and fbzt='发布'\"\n",
    "pattern = r'FROM\\s+([\\w\\.]+)'\n",
    "matches = re.findall(pattern, sql, re.IGNORECASE)\n",
    "\n",
    "for match in matches:\n",
    "    parts = match.split('.')\n",
    "    if len(parts) > 1:\n",
    "        print(f\"数据库名称: {parts[0]}, 数据表名称: {parts[1]}\")\n",
    "        return parts[1]\n",
    "    else:\n",
    "        print(f\"数据表名称: {parts[0]}\")\n",
    "        return parts[0]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_table_names(sql):\n",
    "    pattern = r'FROM\\s+([\\w\\.]+)'\n",
    "    matches = re.findall(pattern, sql, re.IGNORECASE)\n",
    "\n",
    "    for match in matches:\n",
    "        parts = match.split('.')\n",
    "        if len(parts) > 1:\n",
    "            print(f\"数据库名称: {parts[0]}, 数据表名称: {parts[1]}\")\n",
    "            return parts[1]\n",
    "        else:\n",
    "            print(f\"数据表名称: {parts[0]}\")\n",
    "            return parts[0]\n",
    "\n",
    "# 读取xlsx文件\n",
    "df = pd.read_excel('原始数据表.xlsx')\n",
    "\n",
    "# 创建新列并复制“备份SQL查询语句”列的内容\n",
    "df['数据表名称'] = df['备份SQL查询语句'].apply(extract_table_names)\n",
    "# df['数据库名称'] = df['数据表名称'].apply(lambda x: x[0].split('.')[0] if x and '.' in x[0] else '')\n",
    "# df['数据表名称'] = df['数据表名称'].apply(lambda x: x[0].split('.')[1] if x and '.' in x[0] else (x[0] if x else ''))\n",
    "\n",
    "# 将结果保存回原来的xlsx文件中\n",
    "df.to_excel('原始数据表.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
