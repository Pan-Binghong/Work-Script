# 一.机器学习回顾总结

#### 1.线性回归

```
答:线性回归是回归模型，它的公式表达式是y=wx+b,线性回归的原理是希望每个样本点通过wx+b预测结果和真实值误差越小越好，希望wx+b这条 直线更好的拟合数据真实数据分布。适用场景适用于噪音数量少，数据量呈袋装分布的时候比较适用。
```

####  2.逻辑回归

```
答:逻辑回归是2分类模型，它是广义的线性模型，它的公式表达式y=1/1+e-x,（x相当于wx+b）逻辑回归的原理是2分类的值域>0.5为1类，<0.5为0类。适用场景数据量不大，并且噪音数量小的情况。
```

#### 3.随机森林

```
答:随机森林可以做分类任务也可以做回归任务，它是由多棵树构成采取有放回的的形式抽取部分特征和数据样本来构建多棵树，分类：投票，回归：取平均，适用场景噪音数据量不是很多的情况，可以出一版baseline。
```

#### 4.朴素贝叶斯

```
答:朴素贝叶斯主要做分类任务，它的公式是P(AB)=P(B|A)*P(A)=P(A|B)*P(B),朴素指的是特征之间相互独立，适用场景分类任务。
```

#### 5.SVM

```
答:svm主要做二分类任务的，它的适用场景是当有AB两种数据，当少量A数据在B中，同时少量数据B数据在A中可以使用svm，我们采用支持向量进行一个划分，划分的2个依据是第一是这两个数据大部分是可以划分的，第二是AB这两个样本距离支持向量最近的样本点的距离相等，如果低维不可分的情况下，我们可以从低纬度转成高纬度进行分隔，使用的核函数有高斯核函数，多项式核函数，线性核函数。svm的缺失值不能太多，数据噪音不能太多。
```

#### 6.GBDT

```
答:GBDT是集成模型可以做分类任务也可以做回归任务，对残差进行拟合，首先先正常构建第一个树正常预测，接着第二棵树对第一棵树的误差进行一个拟合，以此类推后面的树对前一棵树的误差不断拟合，直到误差为0或者足够小可以接受，构建完毕，它主要用到的是一阶泰勒求导。
```

#### 7.XGBOOST

```
答:XGBOOST是集成模型可以做分类任务也可以做回归任务，对残差进行拟合，首先先正常构建第一个树正常预测，接着第二棵树对第一棵树的误差进行一个拟合，以此类推后面的树对前一棵树的误差不断拟合，直到误差为0或者足够小可以接受，构建完毕，它加入了正则项，它主要用到的是二阶泰勒求导,借助随机森林，对缺失值进行很好的处理。
```

#### 8.GBDT与XGBOOST的区别

```
答:共同之处是都对残差进行一个拟合，不同之处在于 GBDT用到了一阶泰勒求导，XGBOOST用到了二阶泰勒求导，并且加入了正则项，而且还借助了随机森林思想，对缺失值进行很好的处理。
```

#### 9.KMEANS

```
答:属于聚类模型，它的原理是首先先确定几个簇（聚几类），随机选择几个位置，分别计算每个位置和其它样本点的欧氏距离，距离相近的聚在一起，更新中心位置。选择簇的方法:手肘法，图像中选择拐点位置
```

#### 机器学习流程

```
答:首先先观察数据，看数据中是否有异常值，空值，特殊符号。然后分析数据因为机器学习要求可解释性得根据业务场景来选取特征一般选取（30-50）我们项目中都是以深度学习为主，给定的数据量很多我们首选深度学习模型比较合理。
```

#### 10.前馈神经网络

```
答：前馈神经网络，是一种最简单的神经网络，各神经元分层排列，每个神经元只与前一层的神经元相连。接收前一层的输出，并输出给下一层，各层间没有反馈。是应用最广泛、发展最迅速的人工神经网络之一。
```

#### 11.梯度下降

```
答：输入数据经过sigmoid(wx+b)得到下一个神经元的输入，下一个神经元的输入在经过sigmoid(wx+b)得到下一个神经元的输入，以此类推直到最后一层得到预测值，得到预测之以后前向传播这块就算完成了，根据预先提供的真实值通过公式计算真实值与预测值之间的误差，通过反向传播依次向前传递误差，不断调整误差通过前向传播计算误差值与真实的差距，直到误差值接近真实值之后就完成了。然后保存调整好的权重与偏置。
```

#### 12.强化学习

```
答:强化学习是一个自主学习的过程，它由两部分组成，智能体和环境，智能体给环境一个结果，环境给智能体一个打分，然后根据打分结果重新学习
```

#### 13.反向传播

```
答：反向传播用到的是链式求导,说白了反向传播通过前向传播计算真实值与预测值之间的误差，然后通过误差通过反向传播来更新w,b,用到了链式求导的方式，其中更新的时候用到了梯度下降的公式。
```

| 机器学习算法 | 适用任务                               |      |      |      |
| :----------- | -------------------------------------- | ---- | ---- | ---- |
| 线性回归     | 回归任务                               |      |      |      |
| 逻辑回归     | 分类任务                               |      |      |      |
| 随机森林     | 可以做分类任务也可做回归任务           |      |      |      |
| 朴素贝叶斯   | 分类任务                               |      |      |      |
| SVM          | 二分类任务                             |      |      |      |
| GBDT         | 集成模型可以做分类任务也可以做回归任务 |      |      |      |
| XGBOOST      | 集成模型可以做分类任务也可以做回归任务 |      |      |      |
| KMEANS       | 聚类任务                               |      |      |      |

# 二.基础汇总

#### 1.word2vec

```
答：Word2vec两种加速方式：层次softmax,负采样
层次softmax（把多分类问题转化为对各二分类问题）,负采样（把一个多分类问题转化为二分类问题）

负采样：构造负样本，中心词和周围词构造1个正样本，随机从词表中选取6-7个构造负样本，这样一共计算7次就完事，从原来的词表大小数量级别降到7次，大大提升了速度}

训练方式：CBOW，Skipgram，CBOW：用周围词预测中心词，Skipgram：用中心词预测周围词。
```

#### 2.激活函数和常见的损失函数

```
常见的激活函数有Sigmoid，Tanh，Relu，LeakyRelu，Gelu
Sigmoid的取值范围(0，1)  f(x) = 1/(1+e^-x)
Tanh的取值范围（-1，1）
Relu的取值范围（>0带有斜率的一条直线，<0为0）
LeekyRelu的取值范围（>0带有斜率的一条直线(第一象限)，<0为0（第三象限））
Gelu的取值范围(>0带有斜率的一条直线(第一象限),<0在第三象限开始会有一段弧度接下来无限接近于零)
激活函数的作用是为了更好的拟合多项式，将线性变成非线性
常见的一些优化器有:SGD、Adagrad、Adadelta、RMSprop、Adam、Adamax、Nadam、TFOptimizer等等
```

#### 3.线程和进程的区别

```
答：线程用于实现轻量级并发，进程用于实现更稳定的隔离和独立性，通常用于多核处理器上的并行处理。
```

#### 4.深拷贝和浅拷贝

```
深拷贝的含义是：在深拷贝中，不仅复制外部对象，还会递归复制内部嵌套对象，创建全新的对象结构。这意味着原始对象和深拷贝对象之间没有共享引用。
浅拷贝的含义是：在浅拷贝中，只复制了数据结构的外层对象，而不递归复制内部嵌套对象。这意味着原始对象和浅拷贝对象之间共享内部嵌套对象的引用。
总结：浅拷贝和深拷贝的主要区别在于修改浅拷贝中的嵌套对象也会影响原始对象，而深拷贝中的嵌套对象是独立的。
```

#### 5.属性装饰器

```
答：是Python中的装饰器，用于控制类的属性的行为，如访问、赋值和删除。它们允许你在属性的读取和写入时执行自定义的逻辑，通常用于属性的访问控制、数据验证和计算属性等。
```

#### 6.自编码模型和自回归模型有哪些

```
自编码模型：bert
自回归模型：gpt
```

#### 7.全连接层

```
全连接层：（mlp,线性层）根据神经元进行特征识别糅合，最后进行分类。
有多个神经元构成，本层神经元不连接，前后层神经元相连接，每个神经元都是由sigmoid(wx+b)构成，前后层神经元分配一个权重，提取特征做分类用。
原理：首先把所有的特征一起扔到全连接层，全连接层的神经元进行特征识别，识别到了就带能量神经元，然后把特征传入下一层神经元进行高级的特征识别和分类，最后利用softmax计算概率并判断是哪一类。
```

#### 8.LSTM

```
答：LSTM 可以处理长文本信息，它比RNN多了一条记忆细胞，它还有门控机制 ，LSTM三个门控机制：遗忘门 ，输入门，输出门
遗忘门：它的功能是决定丢弃还是保留哪些信息，来自前一个隐藏状态的信息 和当前输入的在信息同时传递 到sigmoid函数当中去，输出值介于0和1之间，越接近0意味着越因该丢弃，越接近1意味着越应该保留。

输入门：它的作用用于更新细胞状态，首先将前一层隐藏状态信息和当前的输入信息传递到sigmoid函数当中去，，将值调整 到0~1之间来决定更新那些信息，0表示不重要，1表示重要。

输出门用来确定下一个隐藏状态的值，隐藏状态包含了先前输入的信息。首先，我们将前一个隐藏状态和当前输入传递到sigmoid 函数中，然后将新得到的细胞状态传递给tanh函数。

最后将tanh的输出与sigmoid的输出相乘，以确定隐藏状态应携带的信息。再将隐藏状态作为当前细胞的输出，把新的细胞状态和新的隐藏状态传递到下—个时间步长中去。

更新细胞：与遗忘门相乘，与输入门相加就得到更新

总结：遗忘门确定前一个步长中哪些相关的信息需要被保留;输入门确定当前输入中哪些信息是重要的，需要被添加的;输出门确定下一个隐藏状态应该是什么。 
```

#### 9.GLM框架

```
答：原理是基于自回归空格填充方法，结合了bert,gpt,T5预训练模型的思想。
输入：
   输入由两部分构成，PartA是mask后的文本序列,Part2是mask跨度的打乱的词，开始用S，结束用E
   采用二维位置编码第一个位置id用来标记Part A中的位置，第二个位置id用来表示跨度内部的相对位置，embedding后都会被加入到输入token的embedding表达中
结构：
   重组了层次归一化和残差连接的顺序；
   使用单个线性层对输出token进行预测；
   激活函数从ReLU换成了GeLUS
   Part A中的tokens彼此可见，但是不可见B中的任意tokens
```

#### 10.simcse是如何训练的

```
simcse是如何训练的
simcse是训练一个编码器，给定一个文本输出一个向量，它是用来做语义相似度的。第一语义相似度先转成语义的向量表示，第二计算这两个向量之间的相似度，语义相似度计算的常见的方式是余弦相似度的一个方式。它有两种训练方式一种是有监督的训练方式，有监督训练方式需要人工构建的把一条文本通过数据增强的方式给它构建成一个相似的样本，正样本构造的方式是随机位置插入符号，负样本是随机找一个给它配制成负样本。一种是无监督的训练方式，负样本是在同一批次每条样本和其它样本构建成负例，正例用到了bert随机mask,把这句话送入到bert两次因为用到了随机mask这样就会生成两个向量。simcse它遵循一个原理尽可能在训练的时候拉近与正样本的距离，让负样本保持均匀分布。
```

#### 11.CRF

```
答：
```

#### 12.HMM

```
答：
```

#### 13.朴素贝叶斯

```
答：朴素贝叶斯通常应用于分类任务中，它的表达式为：P(AB) = P(B|A)*P(A) = P(A|B)*P(B),朴素的意思是特征相互独立
```



#### 14.Linux常用命令大全

```
ls        列出当前目录列表
cd ..      	返回上一级目录
cd 目录名/   进入指定目录
mkdir 目录名 创建新目录
touch 文件名 创建新文件
q!          进入文件后，退出文件(不保存文件)
wq!         进入文件后，退出文件(保存文件)
clear       清空所有指令
pwd              显示当前目录所在位置
python py文件名   运行py文件

查看日志指令
1、tail命令：用于显示文件的末尾内容。
2、head命令：用于显示文件的开头内容。
3、cat命令：用于将文件内容输出到终端。
4、less命令：用于以可滚动的方式查看大型文件。
5、grep命令：用于在文件中搜索特定的内容。
```

#### 15.fp16 fp32 in8 区别

```
芯片算力越大，每秒能够进行的运算次数就越多，执行计算任务就越快。当涉及到深度学习和计算任务时，FP32、FP16 和 INT8是常用的数据类型，用于表示不同的数值精度和存储需求。
单精度（Fp32）：浮点数使用32位表示，具有较高的精度和动态范围，适用于大多数科学计算和通用计算任务。通常我们训练神经网络模型的时候默认使用的数据类型为单精度FP32。
半精度（FP16）：浮点数使用16位表示，相对于FP32提供了较低的精度，但可以减少存储空间和计算开销。按照理论来说可以跑机器学习这些任务，但是FP16会出现精度溢出和舍入误差，所以很多应用都是使用混合精度计算的也就是FP16+FP32模式，简单来说FP16其实在图像处理有更大优势点。
双精度（Fp64）：浮点数使用64位表示，提供更高的精度和动态范围。通常在需要更高精度计算的科学和工程应用中使用，相对于单精度，需要更多的存储空间和计算资源。
固定点数（INT8）：固定点数使用固定的小数点位置来表示数值，可以使用定点数算法进行计算。INT8与FP16、FP32的优势在于计算的数据量相对小，计算速度可以更快，并且能通过减少计算和内存带宽需求来提高能耗。

作者：昊源诺信
链接：https://www.zhihu.com/question/362477980/answer/3125488953
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
```



# 三.BERT

```
1.bert作用是输入一句话，输出一个向量作为整句话的语义表达，是一个自编码模型
2.原理和结构：它的两个训练任务：MLM(多分类)和NSP（二分类）
			MLM（用到了wordpiece主要用来解决oov问题，分词词之后在15%中里的80%要做mask替换，10%换成其它的词，10%保持不变）
			NSP用来判断两句话是不是连续的
			损失函数：loss = loss(mlm) + loss(nsp)越小越好，因为它两做的都是分类任务所以都采用交叉熵损失函数作为它们各自的损失函数。
模型结构：输入层由三个embidding组成：Tokens Embidding(词嵌入)，Segment Embidding(段落嵌入)，Position Embidding(位置嵌入) 
Segment Embidding主要做的是判断哪句话是第一句话哪句话是第二句话。
bert的拼接方式：cls_+ sep  cls+第一句话+sep分割+第二句话
bert的模型结构‘：N-BLOCK,多头注意力机制，残差网络，层次归一化，前馈神经网络（2层）多头注意力机制：多头注意力机制，多头作用一词多意，让一个词在不同的语义场景可以很好的表达。
自注意力机制：Q=K=V 一句话内部 学习词与词之间相互关系（内部学习）
具体步骤：1.分头，线性映射，多组QKV 举例 512/8=64 每个头是64维的
	    2.进入不同QKV语义场景学习，softmax(q*k/根号dk) * v ，q*k作用：计算词之间的相似度，相关性。除以根号dk：防止q*k结果分布在softmax的饱和区(0或者1附近)softmax作用：归一化 0-1之间乘以v的作用：v保留了原始矩阵维度，更新v里面的参数
	    3.合并 按照最后一个维度拼接还原最终的输入维度
		4.每一步的维度转化：比方说2个词  每个词的维度都是64，q * k = 2 * 64, 2 * 64  经过转置 变成 2 * 64 ，64 * 2 = 2 * 2矩阵 除以根号dk进行一个缩放  但是维度不变在经过softmax使值分布在0，1之间。2 * 2   * 2 * 64 = 2 * 64   乘以 2 *  64的意思是对里面的参数都进行一个加权，加入注意力机制在里面。
		5.层次归一化和批次归一化的区别：批次归一化是不同样本在同一纬度做归一化，层次归一化：同一样本在不同维度进行归一化。我们在这里用到了层次归一化。单独考虑一个维度是没有意义的，综合考虑所有维度才有意义。
前馈神经网络：2层  768 -1024 ，1024-768
优缺点：优点：效果好，不需要大量语料，只需要少量的语料做微调就会得到很好的效果。						  
缺点：1.模型太大，推理速度慢，需要做蒸馏或者使用蒸馏模型，蒸馏模型有albert,TinyBERT 2.如果是一篇长文本处理不了，有输入限制的时候，采用滑动窗口法进行一个编码，取平均x向量当作最终的语义表达。3.训练的时候使用了Mask,但微调的时候看不到Mask标识,mlm有10%不变的词就是为了缓解这个问题。
wordpiece作用：为了解决oov问题  未登录词 指的是新造的词，没有任何规律。
```

# 四.transformer

```
transformer可以做机器翻译，文本摘要，它的框架是由encoder-decoder两部分组成。
encoder(6个Block):encoder输入，encoder的子层结构。
decoder(6个Block):decoder输入，decoder的子层结构。
encoder 输入包括：词嵌入+位置嵌入
encoder 子层结构包括：多头注意力机制，残差网络，层次归一化，前馈神经网络。

decoder 输入包括：词嵌入+位置嵌入
decoder 子层结构包括：mask多头注意力机制，残差网络，层次归一化，encoder-decoder交叉注意力机制，前馈神经网络。
decoder 输出：线性层+softmax(词表大小分类)

encoder多头注意力机制：指的是q=k=v 作用：让一个词在不同语义表达更加丰富，softmax(q*k/根号dk)*v
层次归一化：在多个维度进行归一化可以让模型效果更好，批次归一化单独考虑一个维度归一化没有任何意义。
前馈神经网络：2层的网络（2层线性层 512-1024，1024-512）

decoder mask多头注意力机制：为什么用mask:训练的时候语料全给模型，测试的时候decoder是一个字一个字生成，当预测第N个字的时候，是看不到N+1之后的信息的，而训练的时候可以看到后面的词的信息，为了保持训练和预测方式一致，用mask形式来做。

encoder-decoder交叉注意力机制：Q！= K = V, Q是decoder提供的，K,V是encoder的输出
训练的时候，数据是一次性给到模型的，而预测只给encoder的数据，decoder数据是不给的。
decoder生成的时候是从start起始符号开始，当碰到end符号结束，从左到右一个字一个字生成。
transformer的层归一化如何修改其中的两个参数来训练？

Transformer中的层归一化(Layer Normalization)有两个可学习的参数gamma和 beta可以通过修改这两个参数来训练。具体来说，gamma用于缩放归一化后的数据，beta用于平移归一化后的数据，两个参数都是一维向量，长度与层的隐藏单元数相同。

如果需要在训练中修改这两个参数，可以在代码中将它们定义为nn.Parameter，然后在每次训练时更新它们，可以使用优化器(如Adam)来更新可学习参数
```

# 五.GPT

```
gpt是一个语言模型，trandsformer的decoder部分，但是没有交叉注意力机制。自回归模型
原理和结构：由多个block组成，其中结构中包括输入，mask多头注意力机制，残差网络，归一化，前馈神经网络。
多头注意力机制：多头作用 一词多意，让一个词在不同的语义场景可以很好的表达。
		自注意力机制：Q=K=V 一句话内部 学习词与词之间相互关系（内部学习）
具体步骤：1.分头，线性映射，多组QKV 举例 512/8=64 每个头是64维的
		2.进入不同QKV语义场景学习，softmax(q*k/根号dk) * v q*k作用：计算词之间的相似度，相关性。除以根号dk：防止q*k结果分布在softmax的饱和区(0或者1附近)softmax作用：归一化 0-1之间乘以v的作用：v保留了原始矩阵维度，更新v里面的参数。
	    3.合并 按照最后一个维度拼接还原最终的输入维度
		4.每一步的维度转化：比方说2个词  每个词的维度都是64，q * k = 2 * 64, 2 * 64  经过转置 变成 2 * 64 ，64 * 2 = 2 * 2矩阵 除以根号dk进行一个缩放  但是维度不变在经过softmax使值分布在0，1之间。2 * 2   * 2 * 64 = 2 * 64   乘以 2 *  64的意思是对里面的参数都进行一个加权，加入注意力机制在里面。
		5.层次归一化和批次归一化的区别：批次归一化是不同样本在同一纬度做归一化，层次归一化：同一样本在不同维度进行归一化。我们在这里用到了层次归一化。单独考虑一个维度是没有意义的，综合考虑所有维度才有意义。前馈神经网络：2层  768 -1024 ，1024-768。		 
mask多头注意力机制：为啥要用mask机制，因为训练的时候语料全部给到模型，测试的时候decoder是一个字一个字生成的，当预测第N个字的时候，是看不到N+1之后词的信息的，而训练的时候是可以看到后面词的信息的，为了保持训练和预测的方式一致，用mask形式来做。
残差网络：防止梯度消失
层次归一化：在多个维度进行归一化可以让模型效果更好，批次归一化单独考虑一个维度没有任何意义。
概括：gpt一般用于生成任务，也可以做微调任务，但是由于训练方式和bert不一样，所以语义编码没有bert好，所以在编码embidding任务上我们还是首选Bert。
```

# 六.区别

#### 1.bert和GPT区别

```
答：他们的区别主要在，任务类型，训练目标，架构，应用领域，模型大小方面
任务类型方面：BERT 主要用于自然语言理解（NLU）任务，如文本分类、情感分析、问答系统等。它通过双向上下文信息理解文本。GPT 主要用于自然语言生成（NLG）任务，如文本生成、对话生成、机器翻译等。它通过单向生成文本。

训练目标方面：BERT 使用自监督学习的方法，通过遮盖部分输入文本中的标记来预测被遮盖标记的内容。这使得它能够学习文本的上下文表示。GPT 使用自回归（autoregressive）方式，将文本视为一个序列，从左到右逐个位置生成下一个词汇。这使得它能够生成连贯的文本。

架构方面：BERT 使用Transformer 编码器架构，其核心特征是双向自注意力机制，以有效地处理上下文信息。
GPT 使用Transformer 解码器架构，它是一个纯粹的自回归模型，只关注左侧上下文信息。

应用领域方面：BERT 更适用于需要理解文本语境的任务，如阅读理解、情感分析、实体识别等。GPT 更适用于生成文本的任务，如文本生成、对话生成、文章摘要等。

总之，BERT和GPT是两种不同类型的预训练模型，分别适用于不同的自然语言处理任务，且它们在训练方式、架构和应用领域上存在显著差异。
```

#### 2.bert和transformer的区别

```
答：bert是transformer模型的一个变种，它采用了transformer的编码部分，而不使用transformer的解码器部分，Transformer 模型是一种具有自注意力机制的深度神经网络，最早用于序列到序列的任务，如机器翻译。BERT 使用了 Transformer 的编码器来处理单一语言的自然语言理解任务，如文本分类、文本相似度等。
一个主要的区别在于处理输入文本的方式。在传统的 Transformer 中，输入序列是单向处理的，即模型从左到右逐个位置处理。而 BERT 使用了双向处理，它可以同时考虑每个位置的上下文信息，这使得 BERT 在理解语境时更加强大。
BERT 是一个预训练模型，它在大规模文本数据上进行了预训练，学习了文本的表示形式，使其可以用于各种下游任务。
传统的 Transformer 模型通常是为特定任务进行有监督训练，而 BERT 的预训练目标是通过遮盖部分输入文本中的标记来预测被遮盖标记的内容，这是一种自监督学习。
BERT 主要用于自然语言理解（NLU）任务，如情感分析、问答系统、文本分类等，其中需要理解文本的语境和含义。
Transformer 模型可用于各种序列到序列任务，包括机器翻译、语音识别以及各种生成型任务。
总之，BERT 是一种基于 Transformer 架构的模型，它在自然语言理解任务中表现出色，因为它能够双向考虑上下文信息，而 Transformer 是一个更通用的序列到序列模型，用于多种 NLP 和其他领域的任务。
```



# 八.项目总结

### 一.数字医生项目

#### 1.项目背景，产品用途，合作方式

```
项目背景：当时疫情还没开放，在家隔离，不方便就医，去医院害怕感染出了这款产品。
产品用途：根据客户的症状描述，初步诊断大概患有哪些疾病，但不能确诊，我们有合作医生坐诊，医生来自不同医院的不同科室的。
合作的形式：机器人根据对话，出一份诊断报告，医生根据诊断报告进行诊断。
医生坐诊的方式：1.图文问诊（咨询10轮）2.在线问诊视频（20分钟）3.电话问诊（15分钟）
问诊后--医生给出结论，1.来医院检查,2.开药（处方药医院开，非处方药到我们自己的商城开，我们有自己的药店）这个产品很成功，原因是当下患者比较大，咨询费是很好的一个收入点，通过我们的数据显示，收入可观。
公众号：不仅部署到公众号上，主要在app端体现的是数字人的形式，首先打开app端先和数字医生对话，然后出诊断报告，根据诊断报告挂号，诊断报告有个人信息必须填全。
文本摘要(诊断报告)的字段：姓名，电话，年龄，性别，预约时间，科室，医生，机器人诊断疾病，客户描述信息。
附件：针对没有症状的描述信息做一个数据存储（数据收集）存到mysql数据库中
这个产品怎么样：日活2000-3000，经过推广之后达到7000左右，阶段性收入达到十几万
```

#### 2.线下模块

```
项目结构：线下，线上
产品作用：根据症状来查询可能患有哪些疾病

线下模块：
数据来源：公司给的，一些开源数据，网站爬的，合作方给的，(疾病43000条，症状37000条)
```

##### （1）NER（命名实体识别）

```
ner：识别非结构化数据的症状
首先先对数据进行标注，我们选择的模型是bert+bilstm+crf,先出一版baseline,我们优化的方式是数据的优化和模型的优化和响应速度上的优化。我们的数据量有37000条，2个人进行一个标注大约花了10左右的时间，我们采用标注的工具是label studio,我们在标注的时候遇到了一些难点，我们不是专业的人士，不确定哪些症状可以使用，我们先选用了一些开源的数据来进行训练，后面选用半监督形式的数据来进行训练，首先先训练一版结果，拿预测好的结果进行一个审核，修改在送入到我们训练数据当中去，这样我们的数据就扩充好了。还有就是选用ac自动机，通过使用全量数据在ac自动机跑一版结果，它就可以把有症状的数据给挑选出来。后期还有就是选用大语言模型进行一个标注，在标注这方面大语言模型是可以完成的，但效果这方面也没啥提升。
在模型选择我们选用的是bert+bilstm+crf模型，为啥选用这个模型主要是bert能够进行预训练学习bilstm在语义上可以更好的捕捉语义，crf可以在一些规则上进行一个约束。我们最开始的一版baseline准确率acc:88%,f1:0.9,我们优化的方式，针对哪类实体数据预测不好，就对该类型数据做了一个数据增强，还对一些脏数据进行了一个清理，调节了一些参数，最后我们的准确率acc:95%,f1：0.94，数据量使用了37000多条，推理速度慢因为使用bert,因为是线下就不过多考虑它的一个速度，但是在线上的话可以换蒸馏模型，像tinnybert,albert,m3e,bpe这些蒸馏模型，尤其是bpe它的效果和bert差不多，但它速度确实挺快的。在调参这块我们对训练轮次，学习率以及神经元的个数，batchsize，效果也没那么明显.

```

##### （2）命名实体审核

```
实体审核：审核结构化数据符合医学命名规范的症状 二分类 0,1
我们先处理了数据，我们的模型选择的是bert+rnn,然后出了一版baseline，准确率acc:92%,f1:0.93然后针对badcase做了一些优化包括速度上的提升还有模型的替换， 我们的数据量有40000条，20000条正样本20000条负样本，数据标注是一个人标注的花了7天左右的时间，在标注的时候遇到了一些问题我们不是很清楚哪些是符合医学命名规范的，我们找了我们的合作方丁香医生，他将我们给的数据进行了一版筛选，剩下的都是符合命名规范的数据,我们的负样本采用倒序的方式进行一个生成，期间也做过其他的一些操作乱序以及交叉排序都会存在一些噪音。采用倒序的方式准确率还蛮高的，我们也尝试过其它的模型像bert+cnn,bert+线性层，因为我们的数据都是短文本采用rnn相对比较合适，加rnn是因为更进一步对语义信息进行更进一步的提取，我们还用到了cnn 因为cnn卷积核视野有限，需要局部滑动看，不能一次看全部特征，但rnn处理时序数据比较好，综合考虑下还是觉得rnn比较不错。后期经过对badcase的优化，优化方式有脏数据的处理，标注错误的，调节参数，增加数据量，最后准确率acc:97%,f1:0.95。在此期间还有些问题就是推理速度慢，我们也考虑到了使用蒸馏模型但是精度会损失2-3个点，最终这块没有用到蒸馏模型。我们也尝试过调训练轮次，学习率，神经元的个数，batchsize效果都没有太明显，主要提升还在增加数据量这方面，还有对标注不合理的数据进行一个处理。

```

##### （3）知识融合

```
知识融合：将相似的疾病进行一个合并，合并后的症状进行合并去重(例 糖尿病1期，糖尿病2期)
我们先处理数据，我们模型选择的是simcse+faiss，先出了一版baseline，我们的数据量43000，我们是一个标注的用来一天的时间。正样本我们用的是simcse有监督的，正样本是两个相似的样本，负样本是两个不相似的，这块是对疾病进行融合，正样本要求两个相似的样本是很难的，我们也做过其它的一些方法，比如数据增强，把一个疾病增强变成一个相似的疾病，增强的方式有很多比方说加个噪音去个字，效果都不咋好，因为它改变了原有的语义，所以说我们最终用了标点隔断的方式，而负样本是将正样本进行一个倒序变成一个负样本了
正负样本比例是1:1的形式加起来总共是86000条。simcse是双塔模型主要是做相似度计算的他有两个训练形式一个是有监督的一个是无监督的，无监督是不需要标签的，直接一个疾病当作一个正样本，负样本是论文中提到的一个形式它把一句话送入到bert模型中两次用随机mask形式增强出一个embidding向量当作一个相似样本而负样本是与同一批次样本与其它的样本构成负样本，但事实证明无监督没有有监督训练的好。faiss是一个搜索工具，它主要用到了向量的内积，在评估这块我们主要用到了人工评估，大概有五六条不太好的数据，faiss的阈值是
图谱评估存放数据
实体类型（本体）：2个，关系一个，症状：30000，疾病：35000左右
图谱的评估方式：
准确性：数据质量和实际的数量一致
一致性：图谱里面不能有关系或者属性冲突
完整性：图谱覆盖要广，满足业务需求
时效性：及时更新图谱，保证都是最近的数据信息
```

#### 3.线上模块

```
线上模块：
公众号服务 
给客户做关注标识，设定初次回复信息，信息传播(把公众号客户的信息传给主逻辑服务)
```

##### （1）主逻辑服务

```
主逻辑服务：判断客户是不是第一次来
主逻辑服务主要的作用就是判断用户是不是第一次来，redis里面存储了三个字段一个是客户的id,一个是客户上一轮说的话，一个是查询出来的疾病。判断是否是第一次来的依据是通过redis里面是不是存了客户上一次说过的话，如果有的话不是第一次来，如果没有的话就是第一次来，如果不是第一次来就调用句子主题相关模型判断，句子主题相关模型输出的结果是0，1，如果输出的是1的话说明相关，我们就会接ac自动机去数据库中根据症状去查询疾病，如果查询到了疾病就直接返回疾病，如果没有查询到症状我们设置了追问模板，我们追问模板设置了三次，如果三次还没有提取到症状，我们直接启动闲聊机器人，如果返回的结果是0的话，我们直接接GPT闲聊机器人。
如果是第一次来，我们会接ac自动机去提取症状,直接去neo4j数据库中查询疾病，查询到了直接返回疾病，如果没查询到接追问模板，追问也是两轮，如果两轮都没有结果就直接接闲聊机器人，因为我们这个闲聊机器人本身就有一个人疾病回复的功能，我们最终使用大语言模型做的微调，用了常用的问答对进行了一个微调，既有闲聊功能又有疾病回复功能。
```

##### （2）句子主题相关模型

```
句子主题相关模型：判断上一轮客户说的话和本轮说的话在不在一个主题上
先从redis取出一句话和本轮客户说的话，送入到模型中，输出0代表不相关，输出1代表相关，数据来源主要是寻医问药，39健康网，都是单轮数据，数据量7万条正样本是2个客户的问题，负样本是一个客户问题+回答这个问题的倒序，我们的模型选择选用的是bert+线性层，我们这块是线上模块，我们最开始选用的蒸馏模型tinnybert+mlp(312维度)，albert+mlp(768维度)，今年我们选用的是bpe+mlp，因为bpe推理速度快，符合线上标准，和bert差不多，之前选用tinnybert也挺快速度提升了4倍，但是精度会有所损耗损失了一个点，准确率acc:95%,f1:0.94,今年我们用到了m3e，bpe embidding方法,bpe速度相对快一点，优化后的准确率acc:97%，f1值：0.96，我们的优化包括数据的挑选，像2个回复比较短的，回复不完整的一些数据去除掉之后，换了蒸馏模型才达到了这样的一个精度。

ac自动机+实体链接查询
ac自动机的作用是提取客户说的话里面的症状，

```

##### （3）实体链接

```
实体链接主要是当客户所说的话中有症状，但这个症状不符合医学命名规范neo4j中查询不到，我们需要实体链接来做相似度计算，主要是对症状的链接
```

##### （4）闲聊机器人

```
闲聊机器人
我们最开始选用的闲聊机器人是GPT2，自己训练的，找的开源语料清洗质量不是很好，找别人做的，它支持3轮对话，在信息量这个维度上表现的不咋好，我们合作方有些优质的语料，小艺的语料有400万。今年我们用大语言模型微调来做的效果还是蛮不错的。我们后来选用chatglm2模型，这块我们做了很多工作，我们这个模型是为了完成2个任务，第一，具有闲聊能力，第二，如果数据库没有查询到疾病或者特殊问题，启动语言模型对疾病进行回答，所有我们用了少量的医疗问答做了微调，让模型又能闲聊又能回复疾病。因为大语言模型毕竟是生成模型，不能确保回答的都是正确的，所以我们优先走检索式，用生成式兜底，语料我们爬取39健康网，经过清洗一共5万条，训练的时候进行了不同层级对比训练，1万-5万分别测试，训练轮次1000-5000分别测试，最终发现，2000轮次5万数据效果最好。但是在我们训练过程中也碰到到了一些问题，第一出现回复重复问题，经过测试，是训练轮次不足导致的，后来加大训练轮次就解决了，第二丧失了闲聊功能，解决方案后来加入了闲聊语料来解决，我们加入了不同的配比的闲聊语料，5%，10%，15%，20%跨度进行训练，最终得出的结论，15%的闲聊配比，2000轮次，5万数据效果最好。同时我们也对比了baichuan-7b(百川),qianwen-7b(阿里),internlm-7b(上海研究院)都是打榜比较靠前的模型，从回答长度，模型使用量来评测，还是chatglm2效果好。
模型评估这块我们用到的是人工评估，评估的维度有连贯性，信息量，流利性，是否符合事实，进行了多人打分取平均值的人工评估，因为人工评估耗时耗力，我们了自主研发了自动化评估系统。
最终这个模型达到了落地标准，但是有一个问题，就是生成的时候长文本回复比较慢，所以我们采用了流式输出的形式，让客户可以直接直观的看到生成的内容。我们公司有一台A100 80g显存，直接部署速度很快，100-150ms出结果。

数据库：redis(非关系型数据库) mysql(关系型数据库) neo4j(非关系型数据库)
当关系比较复杂，比较深的时候选neo4j,当关系不是很多，部分关系不是很重要的时候选用mysql,redis是以哈希映射进行一个存储。

#### 2.模型是怎么做微调的？

我们使用大语言微调模型想要代替我们数字医生项目中的闲聊机器人。

首先在选模型的时候因为我们的任务主要是中文领域，所以最终我们选取的是chatglm2模型。

其次我们就是对数据进行处理，需要将数据处理成问答对的形式，这样数据才能正常输入模型进行训练。

然后我们刚开始是分别对10000，20000，30000，50000数据量，分别训练1000，2000，3000轮次。然后用不同的模型对测试集数据进行预测，经过对比，发现30000数据量2000批次的模型的回答能力相对其它几个效果是最好的。但是我们发现无论是哪个模型的闲聊功能是丧失了的，这是一个很严重的问题。最终我们是通过在训练数据中分别添加5%，10%，15%，20%的闲聊语料重新训练。最后经过对比我们确定了30000数据量，15%的闲聊语料训练2000轮次的模型做我们的最终模型，接入到我们的数字医生项目中。代替了gpt2模型的闲聊机器人。机器人的回复效果也是得到了显著提升。 

答：我们最开始选用的闲聊机器人是GPT2，自己训练的，找的开源语料清洗质量不是很好，找别人做的，它支持3轮对话，在信息量这个维度上表现的不咋好，我们合作方有些优质的语料，小艺的语料有400万。今年我们用大语言模型微调来做的效果还是蛮不错的。我们后来选用chatglm2模型，这块我们做了很多工作，我们这个模型是为了完成2个任务，第一，具有闲聊能力，第二，如果数据库没有查询到疾病或者特殊问题，启动语言模型对疾病进行回答，所有我们用了少量的医疗问答做了微调，让模型又能闲聊又能回复疾病。因为大语言模型毕竟是生成模型，不能确保回答的都是正确的，所以我们优先走检索式，用生成式兜底，语料我们爬取39健康网，经过清洗一共5万条，训练的时候进行了不同层级对比训练，1万-5万分别测试，训练轮次1000-5000分别测试，最终法向，2000轮次5万数据效果最好。但是在我们训练过程中也碰到到了一些问题，第一出现回复重复问题，经过测试，是训练轮次不足导致的，后来加大训练轮次就解决了，第二丧失了闲聊功能，解决方案后来加入了闲聊语料来解决，我们加入了不同的配比的闲聊语料，5%，10%，15%，20%跨度进行训练，最终得出的结论，15%的闲聊配比，2000轮次，5万数据效果最好。同时我们也对比了baichuan-7b(百川),qianwen-7b(阿里),internlm-7b(上海研究院)都是打榜比较靠前的模型，从回答长度，模型使用量来评测，还是chatglm2效果好。
意义是：我们自己做这个工作的意义是为了通过这个大语言模型来拉融资，如果使用其他人的模型涉及到了侵权。
```

#### 4.优化

```
优化：
1.相应速度ms,性能：es耗时100ms，faiss耗时50ms
2.模型上的优化:调参，学习率，训练轮次，层数，dropout,网格参数，换蒸馏模型tinybert,albert
3.数据层面：badcase找出来,训练集测试集，验证集的划分一般是7:2:1或者是8:1:1,测试集的数据不能在训练集中出现否则会发生过拟合的现象，我们测试集的选取必须涵盖所有类别，不覆盖所有类别可能会出现预测的时候会出现有的类别预测不好，所以要保证类别的一个均衡性。优化方案看看是不是数据少了，加一些数据，或者看看数据里面的噪音数据处理干净没，还有就是看看有没有标注错误的。
整体流程
首先先分析数据，看看是做啥任务的然后选择模型，然后对数据进行标注，接下来开始训练数据，出一版baseline，定位到那类的badcase相对来说比较多，然后处理哪一类数据进行一个优化，优化方案主要是针对badcase进行一个优化，查看是否存在脏数据，增加数据量，查看标签是否有误，重新训练一版结果，再观察badcase是否减少，迭代训练.
```

#### 5.难点，以及遇到那些坑？

> ```
> 难点：
> ner数据标注，因为ner数据量不是很多得进行数据增强，要进行标注所以就是半监督，第一批语料如何找出来，根据已有的症状词典，通过全量语料命中，命中的话说明这条语料有症状，然后拿有症状的语料进行一个训练。
> 还有就是审核模型指标上不去，原因是因为负样本没有构造好，采用倒序形式来构造，还有就是推理速度慢换蒸馏模型。
> 如何部署的：我们有三四台服务器，采用分布式不同的服务部署到不同的服务器上面。我们还使用了docker打包，fastapi封装，supervison守护进程，还有就是并发量的问题，可以采用nginx负载均衡来缓解，对于并发量大的可以采用熔断机制，分布式缓存，分布分表来缓解。
> 高并发：增加服务器，分布式缓存（多个数据库进行一个缓存），熔断机制（先放一部分用户进入，剩余用户被阻挡在外，等前面一部分消耗完再放另一部分用户），数据库-分库分表（将一张表分成多个表），负载均衡nginx(配置文件)
> ```
> 

###  二.大语言模型训练

#### 项目背景，项目流程

##### 1.项目背景

```
项目背景:随着LLM兴起，未来是大模型时代，公司要自主研发自己的大模型，同时开发自动化评价系统，用来解决公司闲聊业务模块问题，同时想通过自动化评价系统替代人工评价，从海量的数据中挑选出优质的语料数据，构造我们自己的数据库。

大语言模型训练	
项目背景：
	随着llm的兴起，未来是大模型的时代，公司要自主研发自己的大模型去拉融资，同时开发一个自动化评价系统，解决公司产品闲聊业务模块的问题的同时，通过自动化评价系统替代人工评价，从海量的数据中挑出优质的语料数据，构建我们自己的语料库
	
项目流程：
	首先训练一个拥有回复能力的llm模型，我们选用的是悟道的无监督语料和glm的Glm-6B框架进行训练
	然后，用训练好的glm-6B模型进行SFT有监督的微调训练，让模型向着我们希望的方向进行回答
	接着对模型进行RLHF（基于人类反馈的强化学习）训练，需要训练一个奖励模型，我们选择的是glm0.3B，Pangu-350M，让奖励模型对问题生成的多个回复进行排序打分
	训练过程中我门采用了PPO策略进行优化训练，最终保存模型
	
训练数据：
	我们的训练数据选用的是开源的悟道数据，大概5900W语料200多个G，涵盖了游戏，经济，体育，法律，教育，农业等30多个类别，当然这些数据不能直接拿来用，需要进行数据清洗，这是个很重要也很繁琐的工作，我们找出了大概20多种脏数据，比如说：带平台标签的，识别为广告的，问题答案重复的，有脏话，敏感词，方言的，有时效性的回答等等，进行了数据清洗后，得到了3000W条语料，尽量保证了各种类别的数据均衡，然后进行了模型的预训练。
	悟道数据的字段包括id，id编码，标题编码，数据类别，标题，文本内容content共6个字段

	我们公司有1张A100，8张4090，总算力有360G，我们进行训练需要350个G左右，刚好可以达到需求，整个训练过程，大概花费了480个小时
	
SFT和RLHF：
	在进行有监督的微调和强化学习的时候，我们挑选了20W条数据来做，我们将数据都处理成了统一的json格式，一条数据中有三个字段：prompt，answers和prefix，prompt为问题，prefix为任务类型，answers对应的是一个列表的格式，包含了多个answer及对应的分值，这个分值对应的是对每个回答的一个打分，有-1，0，1，2，3五个分值。
	在进行有监督微调的时候，我们只调用prompt字段和answers字段中的第一个answer，不包括分值score。
	训练奖励模型的时候，会调用prompt及answers中的所有回答，包括分数。
	在进行强化学习时，会做一个打分排序，一个prompt生成5个答案，奖励模型会对生成的答案进行打分，排序。
	我们生成一个答案大概耗时800-1700ms

参数：
	预训练：我们调整过的超参数主要有：隐藏层层数，隐藏层大小，多头注意力的头数，学习率，训练精度，seq最大长度等
	SFT：我们调整的超参数主要有：最大词输入长度，日志保存步数，模型保存步数，学习率，训练批次，验证批次，还有deepspeed的config文件
	Reward：我们调整的超参数，主要有：模型路径，分词器路径，学习率，训练集路径，训练批次，梯度累计步数，训练轮次，验证集批次，验证集路径
	RLHF：我们调整的超参数有：SHF模型路径，Reward模型路径，学习率，训练批次大小，PPO训练批次大小，及zero_stage大小等等
	
	
碰到的难点：
	在模型的整个训练过程中我们也是碰到了很多问题，浪费了我们很多的时间和精力去解决，比如说：
	1.模型训练时没有效果，这个是因为代码有bug，解决方式就是在训练之前，先用小规模的数据和模型参数进行代码测试
	2.loss曲线发现有不少尖峰，这是因为在某一批次时反复重新计算同一段batches导致，解决方式就是：调整参数观察结果，我们还将激活函数进行了更换，将gelu更换为relu
	3.还有GPU掉线问题，任务挂起，CUDA错误，NCCl错误问题，训练不稳定问题，这个大部分原因都是因为版本不匹配等问题引起的
	
自动化评价系统：
	大模型训练需要很多的优质语料，可以通过自动化评价系统从不同纬度选择优质对话语料，同时在模型评估上替代人工评估打分。
	人工评估方式：
		多人标注，取平均值的方式：
		维度选择：连贯性，信息量，流利性，是否符合事实，迷幻（是否胡说八道）
		定义评估标准：打分区间0-2，采用连续型规则，分为4个区间：0-0.5，0.5-1，1-1.5，1.5-2，制定一套打分规则，所有人都按照规则进行打分标注，每个维度都制定了对应的规则，以连贯性为例：连贯性指得时问题和答案之间是否有清晰的逻辑关系，是否能形成一个连贯的整体。我们设置了：
		0-0.5：答非所问
		0.5-1.0：回答相关性不强，简介回答，万金油回复
		1.0-1.5：直接回答问题，但是信息量不足，回答的不是很有用
		1.5-2：答案回复直接，连贯性强，信息量大，回答比较有用
	
	人工评估耗时耗力，一个人标1000条数据就要花费大概1天的时间，所以我们就想用模型来帮我们进行打分，做一个自动化评价系统，
	我们采用的做法就是：针对不同的维度分别建模，取加权平均得分的方式，这里我们主要进行了连贯性，流利度和信息量三个维度的建模，是否符合事实以及迷幻性这两个维度，因为缺少可用的数据的问题，符合事实这个维度，没办法进行，迷幻性指的是多轮对话中回复胡说八道的问题，而我们的评估方式针对的是一问一答的情况，所以也没办法进行这个维度的建模，这不仅仅是我们的问题，也是业界一直难以解决的问题，我们的模型目前最多支持3轮对话。
	其中连贯性，我们参考的是quantiDCE这篇论文中提到的模型，论文中主要提到的就是mlr和KD的一个应用，你输入问题和答案，输出0-2的连续型分数
	流利度和信息量模型，我们同样参考了一篇开放域模型评估的论文
	
	最终我们的自动化评估得分是这样计算的：0.4x连贯性+0.3x流利+ 03 x 信息量 =  分数 

总结：
	构建好我们的自动化评估系统后，我们对自己训练好的大模型也做了评估，最终得到的分数也达到了老板的要求，所以也就这样交差了，后续就没再跟进了。
```

#### 2.项目流程

```
项目流程：
1.大语言模型训练流程：
chatgpt训练流程：文字接龙使用无监督语料训练使用GLM框架进行训练，GLM-6B（悟道，书生万卷）意义是训练一个模型能够有基础的问答能力，但是回复的问题有的是没用的,使用训练好的glm-6b进行SFT有监督的微调训练，主要是让模型朝着我们想要的方向学习，RLHF基于人类反馈的强化学习，设置奖励模型选择的是glm-0.3B，对问题生成的多个回答进行排序打分，最后使用ppo策略优化训练，最终保存模型。

PPO （proximal policy optimization，PPO）近端策略优化，核心思想是限制策略更新幅度，以达到稳定、高效的训练结果。
PPO 算法之所以被提出，根本原因在于 Policy Gradient（策略梯度） 在处理连续动作空间时 Learning rate 取值抉择困难。Learning rate 取值过小，就会导致深度强化学习收敛性较差，陷入完不成训练的局面，取值过大则导致新旧策略迭代时数据不一致，造成学习波动较大或局部震荡。除此之外，Policy Gradient 因为在线学习的性质，进行迭代策略时原先的采样数据无法被重复利用，每次迭代都需要重新采样。
具体来说，PPO算法使用了两个损失函数：第一个损失函数是近端比率裁剪损失，用于限制策略更新幅度；第二个损失函数是价值函数损失，用于优化策略。两个损失函数的加权和就是PPO算法的总损失函数。

chatglm和llama的区别：
训练语料方面：chatglm支持中英双语，而llama训练的的中文的语料只有0.13%，英文语料有89.7%，对英文很友好

训练方式上，chatglm只进行了预训练和SHF阶段并辅助以RLHF，llama进行预训练、有监督微调（SHF）、基于人类反馈强化学习（RLHF）阶段，其中RLHF阶段训练了两个奖励模型分别在有用性和安全性更加符合人类偏好，使用拒绝采样和PPO算法

模型结构方面：chatglm使用的glm框架，而llama相对于transformer架构做了以下改动

1. 前置的均值归一下(RMSNorm)，不在使用层次归一化（layernorm）,将RMSNorm前置让训练会更加稳定。
2. 在Q、K上使用旋转式位置编码，token长度具有更好的外延效果。。
3. 线性层不使用relu激活函数，使用silu激活函数。
4. 使用了(GQA)Group Query Attention，多个查询头关注相同的键和值头，减少推理过程中 KV 缓存的大小，并可以显著提高推理吞吐量。

如果我们微调中文模型可以选择chatglm,如果是英文模型我们可以选择llama

baichuan是支持中英双语，和 LLaMA 一样的模型架构设计，位置编码使用ALiBi位置编码

glm
原理：
​           基于自回归空格填充方法，结合了bert、gpt、T5预训练模型的思想
​			输入：
​					输入由两部分构成，PartA是mask后的文本序列,Part2是mask跨度的打乱的词，开始用S，结束用E
​					采用二维位置编码第一个位置id用来标记Part A中的位置，第二个位置id用来表示跨度内部的相对位置，embedding后都会被加入	到输入token的embedding表达中
​			结构：
​           		重组了层次归一化和残差连接的顺序；
​          		 使用单个线性层对输出token进行预测；
​          		 激活函数从ReLU换成了GeLUS
​          		 Part A中的tokens彼此可见，但是不可见B中的任意tokens

微调方式：
大语言模型的微调方式有：Fine-Tuning、Prompt-Tuning（P-Tuning）、Prefix-Tuning、P-Tuning-V2、Lora、QLora、RLHF

Fine-Tuning：
将预训练模型与少量特定任务数据一起继续训练。多用于bert、gpt预训练模型微调

Prompt-Tuning：
微调的是模型的输入，制作一个提示模板、对提示模板进行编码（bilstm+mlp）再与input_embedding进行拼接一起作为输入，固定PLM的所有参数，只更新模板进行编码参数，优点是微调的参数量小，缺点是预训练模型参数量不能过小，任务不通用，否则效果不好。

Prefix-Tuning：
微调的是模型的输入，不同于P-tuning的是，在模型输入前添加一个连续的且任务特定的向量序列，固定PLM的所有参数，只更新优化特定任务的prefix。优点是微调的参数量小，缺少通用性，缺少深度提示优化

P-Tuning-V2：
该方法是在每一层都加入了Prompts tokens作为输入，而不是仅仅加在输入层，缺点：训练参数量增多，优点：增强通用性，在所有任务上都能与全量微调相媲美，多用于ChatGLM

LoRa：
LoRa属于部分参数微调，它就是在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩，用随机高斯分布初始化 A，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵 B ，训练完成后，将 B 矩阵与 A 矩阵相乘后合并预训练模型参数作为微调后的模型参数，是当下最流行的微调方式

QloRa：
使用一种新颖的高精度技术将预训练模型量化为 4 bit，然后添加一小组可学习的低秩适配器权重，这些权重通过量化权重的反向传播梯度进行微调。它可以减少内存的使用，足以在单个48GB的GPU上微调65B的参数模型，同时保留完整的16位微调任务性能。

RLHF：
1、人工构建精良数据集对预训练模型进行微调（LM）
2、给微调后的模型一个prompt 生成3-4个答案，对答案进行排序，将回答对放到RW模型中进行打分训练生成一个奖励模型（RW）
3、用强化学习方法微调LM，使用PPO策略，解决学习率的取值问题，用来限制策略更新幅度，通过近端比例裁剪损失和价值损失之和来控制
```

#### 3.chatglm-6b可以改动的参数有哪些？

```
num-layers 28 层数
hidden-size 4096 隐藏层单元数
num_attention-heads 32 注意力头数 32 
seq-length 2048 输入句子的长度
```

#### 4.自动化评价

```
自动化评价系统搭建：
项目背景：大模型训练需要很多优质语料，可以通过自动化评价从不同维度选择优质对话语料，同时在模型评估上替代人工评估打分。
```

#### 5.人工评估方式

```
2.人工评估方式：
多人标注：取平均值，最终采用加权求和的方式
维度选择：连贯性（第一句话和第二句话是否是连贯的  两句话完全不相关），流利性（符合正常人说话，没有语法错误，用词是否准确），信息量（这句话信息足不足，包不包括很多信息量），是否符合事实，迷幻性（多轮对话回复是否胡说八道）
定义评估标注：0-2用的是连续性规则，0-0.5（两句话完全不相关的），0.5-1（间接性回复像万金油油回复的），1-1.5（像回复你说激活函数有哪些只回答比方说有sigmoid relu ....后面也没有过多的介绍，信息量不是很足的话），1.5-2（不仅回复而且还有解释，回复比较充分的时候）。
大模型训练需要很多优质语料，可以通过自动化评价系统从不同的维度选择优质对话语料，同时可以在模型评估上替代人工评估打分，在一定程度上也可以作为奖励模型进行大语言模型训练。

人工评估方式：
	采用的是多人标注，取平均值的打分方式
	维度选择：连贯性，信息量，流利性，是否符合事实
	评估标准：采用的是0-2的连续型打分规则，分为4个区间0-0.5，0.5-1，1-1.5，1.5-2，3个人理解标注规则，独立对数据进行打分标注
	标注的数据样式：问题，答案，连贯性，信息量，流利性，是否符合事实   取3个人在不同维度的平均值，耗时耗力

自动化系统框架：
	针对不同维度分别建模，取加权平均得分作为最终的评估分数
	连贯性：我们参考的是quantiDCE这篇论文，论文里主要采用的是mlr+KD，方式：输入问题和答案 输出0-2的连续型分数
	流利度，信息量：我们参考的是开放域模型评估的一篇论文Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation
	是否符合事实：simcse + 池化 + mlp 参考美团的冠军方案
	
	最终打分：0.4*连贯性 + 0.2* 流利性 + 0.2*信息量 + 0.2*是否符合事实
```

#### 6.评估标准是如何定义的：

```
评估标准是如何定义的：
当时我们定义打分规则的时候选用了三个维度上制定了一个打分规则，分别是连贯性，信息量，流利度上，下面我拿连贯性这个维度来讲述一下我们是如何在这个维度上定义的打分规则。0-0.6生成的文本几乎没有连贯性，句子之间的转换非常不流畅，难以理解。0.6-1.4生成的文本有一些连贯性，但存在明显的断裂或句子之间的转换不够自然流畅。
1.4-2.0生成的文本在结构和逻辑上连贯，句子之间的转换自然流畅。

定完三个人理解标注规则标注的数据样子是从开源数据中采集下来的它的数据样式是一个问题一个答案，在五个维度上连贯性，信息量，流利性，是否符合事实，迷幻（取3个人在不同维度的平均值）使用加权求和取平均值的方式，先是三个人在了解标注规则之后一个维度上取平均值，这样每个维度都有一个平均分，然后根据每个维度上都有各自的一个权重，平均分*权重相加再求和得到最终的一个打分，如果分数高说明在这五个维度上表现都很好说明是条优质语料。
```

#### 7.自动化系统框架

```
自动化系统框架：
针对不同维度分别建模，通过模型进行一个预测，再通过我们给的权重进行一个加权求和，我们在连贯性维度选用的论文是quantiDCE mlr+KD 一个是机器学习的排序，一个是模型蒸馏，剩下的两个维度一个是流利度，一个是信息量我们也是选择了一篇开放阈生成一句话的一篇论文，是否符合事实选用的是simcse+池化+mlp,参考的是美团的冠军方案，最后在四个维度它的权重是0.4*连贯性+0.2*流利性+0.2*信息量+0.2*是否符合事实=分数
```

#### 8.打分规则如何定

```
1.按照连贯性来打分, 
连贯性指的是模型生成的文本在逻辑上的衔接和一致性。它关注的是生成文本内部的连贯性，即文本中的句子之间是否有清晰的逻辑关系，是否形成一个连贯的整体。连贯性评估主要关注文本的内部结构，以确保生成的文本在语义和逻辑上是一致的，没有信息冲突或矛盾。较高的连贯性得分表示生成文本更加流畅、准确和连贯。

区别相关性和连贯性
连惯性更关注的是上下文之间的逻辑, 
相关性更关注的是问题与答案之间的相关性
举例
问题: 今天天气怎么样啊? 
连贯性强: 今天天气很不错, 一会咱两去打球呗? 
相关性强: 今天天气很不错啊, 阳光明媚, 还有小风吹着。[这个句子连贯性也不弱]

分为4个打分区间, 每个区间都从四种四类型的问答举例
问句  陈述句
陈述句 陈述句
问句 问句
单句 多句
0 ~ 0.5 (答非所问)
1. 今天天气怎么样啊?    昨天运气不错 / 有个电影不错
2. 今天天气真不错          昨天运气不错 / xx 手机真垃圾
3. 今天天气怎么样啊?     昨天你去哪了? / 走, 吃饭去?
4. 今天天气怎么样啊?     诶, 你昨天去哪了? 是不是看电影不叫我  
0.5 ~ 1(回答相关性不强 /  间接回答 / 万金油回复)
1. 中午吃的啥呀?  你是不是也吃麻辣烫了 / 
2. 今天中午吃麻辣烫了  嗯,今天食堂见到你了
3. 今天中午吃的啥呀?  今天你去食堂了?
4. 今天中午吃的啥呀?  今天你在学校吃了? 听说有个菜不错
1 ~ 1.5(直接的回答了问题, 但信息量不是那么的足, 回答的不是很有用)
1. 常见的激活函数有哪些?  Sigmoid, Tanh函数, ReLU函数
2. 我刚刚发现我昨天写的wps文档没保存/ 啊,你真倒霉/ 看下云端
3. 常见的激活函数有哪些?  Sigmoid, Tanh函数, ReLU函数, 你还知道更多激活函数嘛? 
4. 你知道ReLU激活函数 是干嘛的嘛? 是的, 我知道, 是一种常用的非线性激活函数。 应用于深度学习中的神经网络
1.5 ~ 2(答案回复直接, 语言连贯性强, 信息量大 / 是比较有用的回答)
1. 常见的激活函数有哪些?  Sigmoid, Tanh函数, ReLU函数, 其中每个再详细解释一下
2. 我刚刚发现我昨天写的wps文档没保存/ 你可以看一下云端有没有保存, 具体方法是: xxxxx
3. 常见的激活函数有哪些?  Sigmoid, Tanh函数, ReLU函数, 其中每个再详细解释一下, 你还知道更多激活函数嘛? [个人认为回答是问句就应该直接打到1.5以下]
4. 你知道ReLU激活函数 是干嘛的嘛? 是的, 他在输入为正时直接返回该值，而在输入为负时返回0。 它还不容易造成梯度消失问题。
```

#### 8.开源数据清洗

```
开源数据清洗：
基于规则的噪音过滤：
1、删除在对话中的平台标签
2、从网址字符串中删除文本
3、对话数超过30的会话拆分为多轮对话数少于30的会话
4、在一个句子中仅保留重复超过6次的短语或单词
5、如果回答太长或太短，则删除对话
6、如果识别为广告则移除对话
7、如果回复中90％的三元组是高频三元组，则删除对话
8、如果回复具有某些特定形式的通用回复，则删除对话
9、删除回复与帖子相同的对话
10、脏话，敏感词和方言
11、有专业术语
12、名称，称谓和未知缩写
13、特殊符号和表情符号
14、平台标志，例如与广告，图片和视频相关的单词
基于分类器的过滤：
15、回复不流畅或句子中有严重错别字
16、回复的信息不完整
17、对话的主题是有时效性的
18、帖子中未提及的节日，地点，性别和时间出现在回复中
19、帖子和回复无关
```

#### 9.超参数

```

```

#### 10.大语言模型主要数据来源？

```
数据来自于悟道:7300w，悟道数据5900w,github开源数据 1400w,书生万卷1T
悟道：200G 5900w
维基百科：100w
百科问答：150w
社区问答：410w
翻译语料 520w
书生万卷 2T文本1T图像视频1T
清洗后的数据是3000w数据
```

#### 11.数据形式

```
悟道数据的形式
{
        "id": 1,
        "uniqueKey": "2edd2b7d5cf24f8d718abe8aeb5e4f42",
        "titleUkey": "fe160ea4dee415011d80cc8103a35ef2",
        "dataType": "农业",
        "title": "云南剧毒眼镜王蛇居民区闲逛 长4米重6.2公斤",
        "content": "云南剧毒眼镜王蛇居民区闲逛 长4米重6.2公斤 图为该剧毒眼镜王蛇长4米，重6.2公斤7月29日晚，镇沅县森林公安民警"
    }

书生万卷数据的形式   
全英文类别 类别8个，有高考，法律，维基百科......
{
    "id": "BkORdv3xK7IA0HG7pccr",
    "content": "\\*诗作[222]\n录自索菲娅·马克思的笔记本"
}

有监督微调数据，奖励模型训练数据样例
{"prompt": "在金属导体中通电时电子会受电场力作用做定向形成电流，那正电荷也受电场力作用却为何不动？", "answers": [{"answer": "正电荷就是金属阳离子了,金属晶体的基本结构就是阳离子组成的\"骨架\"--晶胞.阳离子若是会移动,晶胞就会变形而受破坏,导电时的微弱电场是不可能提供这么大的能量的.", "score": 1}], "prefix": "回答："}

总结：有监督这个模块只用到了两个字段一个prompt，answers,而在奖励模型这块用到了score这个字段，对回答的进行一个排序打分，可以让模型知道哪个回复好。奖励模型可选取 pangu-350M
```

#### 12.算力	

```
算力 多机多卡 A100 80G 4张，单机单卡A100 80G 1张，4090 24G 8张，训练时常是480多个小时，3000w数据
标注，有监督数据量有20w数据要求覆盖所有类型，强化学习打分排序，一个prompt生成3个答案，三个答案送入到奖励模型各出分数，根据这个分数从高到低进行一个排序。
```

#### 微调方式

```
大语言模型的微调方式有：Fine-Tuning、Prompt-Tuning（P-Tuning）、Prefix-Tuning、P-Tuning-V2、Lora、QLora、RLHF

Fine-Tuning：

将预训练模型与少量特定任务数据一起继续训练。多用于bert、gpt预训练模型微调

Prompt-Tuning：

微调的是模型的输入，制作一个提示模板、对提示模板进行编码（bilstm+mlp）再与input_embedding进行拼接一起作为输入，固定PLM的所有参数，只更新模板进行编码参数，优点是微调的参数量小，缺点是预训练模型参数量不能过小，任务不通用，否则效果不好。

Prefix-Tuning：

微调的是模型的输入，不同于P-tuning的是，在模型输入前添加一个连续的且任务特定的向量序列，固定PLM的所有参数，只更新优化特定任务的prefix。优点是微调的参数量小，缺少通用性，缺少深度提示优化

P-Tuning-V2：

该方法是在每一层都加入了Prompts tokens作为输入，而不是仅仅加在输入层，缺点：训练参数量增多，优点：增强通用性，在所有任务上都能与全量微调相媲美，多用于ChatGLM

LoRa：

在预训练好的模型结构旁边加入了A和B两个结构，A的输入维度和B的输出维度分别与原始模型的输入输出维度相同，而A的输出维度和B的输入维度是一个远小于原始模型输入输出维度的值，在训练时只更新A、B的参数，预训练好的模型参数是固定不变的，在推断时将AB与W合并。是当下最主流的参数高效微调方式。

QloRa：

使用一种新颖的高精度技术将预训练模型量化为 4 bit，然后添加一小组可学习的低秩适配器权重，这些权重通过量化权重的反向传播梯度进行微调。它可以减少内存的使用，足以在单个48GB的GPU上微调65B的参数模型，同时保留完整的16位微调任务性能。

RLHF：

1、人工构建精良数据集对预训练模型进行微调（LM）

2、给微调后的模型一个prompt 生成3-4个答案，对答案进行排序，将回答对放到RW模型中进行打分训练生成一个奖励模型（RW）

3、用强化学习方法微调LM，使用PPO策略，解决学习率的取值问题，用来限制策略更新幅度，通过近端比例裁剪损失和价值损失之和来控制
```



#### 13.大语言模型训练遇到了哪些问题

```
大语言模型训练遇到了哪些问题
第一个问题是：代码有bug导致训练作废，
第二个问题是在训练的时候loss不稳定，反复去调整超参数，
第三个问题是发现超参数有不少尖峰（loss异常）最后还换了激活函数将Gelu换成Relu，
第四个问题GPU掉线等硬件问题，CUDA错误，任务挂起，NCCL错误，代码bug,训练不稳定再次发生。

大模型推理速度慢如何解决：流式输出，提高硬件显存提高
```



### 三.百科问答机器人

#### 1.项目背景，项目结构

```
项目背景：我们这个项目是个医院做的，我们做的这个项目是为了缓解医院的一个压力，使用百科问答机器人可以提前回答患者的各种问题，丰富医院的一个His库(Hospital Information System) 
项目包括：线下部分-知识图谱构建，线上部分大意图分类（6类），小意图分类（13分类）
```

#### 2.大意图分类

````
大意图分类（6类意图分类）：接受意图（客户对机器人的回复表示肯定），诊断意图（和疾病症状相关的意图），打招呼意图，结束意图，机器人意图，否认意图（表示否认的语言回复）数据量有24000条，比例是1:1,数据来源是合作方给的一部分数据还有一些是开源的数据还有些是通过数据增强的方式生成的，用到的模型是模板匹配+tinnybert+rnn，准确率达到98%
1：接受：客户对机器人的回复表示肯定
```
举例：
机器人：xxx疾病的症状是这样么？ 客户回复：是的 好的 OK 等等 表示肯定的回复
```
2：诊断：和疾病症状相关的意图
```
举例：
客户：我发烧感冒什么原因 
```
3：打招呼：
```
举例： 你好等等
```
4：结束
```
举例：byebye 再见等回复
```
5：机器人：
```
   举例：
    客户问：你是机器人吗？ 你是真人吗？ 机器人回复：我是智能机器人 很高兴为您服务
```
6：否认意图：表示否认的词语回复
```
举例：
机器人: 你问的是肺炎相关么，客户：不是
```

数据量：6000条  每个样式 1000条    1：1比例

数据来源：合作方给的数据中挑出一部分+开源数据找的+数据增强的

做的方式：模板匹配+   tinnybert+rnn    准确率98%  (312维度  4层)
````

#### 3.小意图分类

```
小意图分类（13意图分类）：疾病的定义，疾病的病因，疾病的预防，临床表现(病症表现)，相关病症，治疗方法，所属科室，传染性，治愈率，治疗时间化验/检查方案，禁忌。
模型：模板匹配+tinnybert+cnn
rnn与cnn的区别是：rnn是处理序列，cnn主要用到了卷积核的形式，他只能看到局部的特征它需要多个卷积核将特诊给拼接起来，再通过全连接的方式进行分类。
```

4.置信度怎么定义的？

```
通过模型计算出置信度分数，设置0.4和0.8两个阈值，小于0.4定义为‘否定’  0.4-0.8定义为‘怀疑’  大于0.8定义为‘接受’
```

#### 5.槽位填充

```
槽位填充：
疾病槽位，抽取到实体的名字，通过cypher语句根据疾病来查询对应的症状，查询出来该以怎样的模板进行一个回复，置信度的类别标签（否定小于0.4，怀疑（0.4-0.8），接受(>0.8)），当置信度小于0.4的时候改以怎样的模板进行一个回复。
回复模板或者追问模板：
打招呼意图触发，再见意图触发，否认意图触发，机器人意图触发。

"定义": {
    "slot_list": ["Disease"],          
    "slot_values": None,          # 抽取到的实体名字
    "cypher_template": "MATCH(a:疾病) WHERE ![img](file:///C:\Users\Administrator\AppData\Roaming\Tencent\QQTempSys\`7_{~]GF$3{MOQ4V_}PH]YC.png)a.name='{Disease}' RETURN a.desc",   #查询语句
    "reply_template": "'{Disease}'是这样的：\n",    # 回复模板
    "ask_template": "请问您想问的是'{Disease}'的定义吗？",    #置信度  在0.4-0.8 追问模板
    "intent_strategy": "",        # 存置信度的类别标签   小于0.4：deny 否定   0.4-0.8：doubt 怀疑      >0.8:accept 接受
    "deny_response": "很抱歉我没有很理解您的意思呢~"   # 小于0.4 返回的模板
  },
  

6类意图识别后 触发模板回复

gossip_corpus = {
  "greet": [     #打招呼意图触发
    "hi",
    "你好呀",
    "我是智能医疗问诊机器人，请问有什么可以帮助您吗？",
    "hi，您好，您可以叫我小小",
    "您好，您可以问我一些关于疾病诊断的问题哦~"
  ],
  "goodbye": [       # 再见意图触发
    "再见，很高兴为您服务。",
    "bye",
    "再见，感谢使用我们的服务。",
    "再见，祝您身体健康。"
  ],
  "deny": [        #否认意图触发
    "很抱歉没能帮到您",
    "I'm sorry",
    "那您可以试着问我其他问题呢~"
  ],
  "isbot": [
    "我是小小，您的智能健康顾问",
    "您可以叫我小小哦~",
    "我是医疗诊断机器人小小"
  ]
}
```

### 四.知识图谱构建    

#### 1.项目背景

```
项目背景：给医院做的，为了缓解医院的压力，使用百科问答机器人提前回答患者的各种问题，丰富医院的HIS库。
```

#### 2.如何构建知识图谱

```
如何构建的知识图谱：
构建的时候我们参考的是ULMS医学schema框架借助了高层复用底层适配的方式。其中高层本体包括，第一层实体，事件，第二层实体包括物理实体和概念实体，事件包括现象和过程,活动，其中我们做的是静态图谱，不涉及事件和活动，高层本体定义好了，底层的本土我们一开始也想采用ULMS的底层本体，毕竟这个schema也是医药方面的，但是这个图谱对于我们的业务需求有些复杂冗余，所以我们针对自己的业务需求重构底层。
构建的思路是，我们搜集了客户常见的问题，医院有这方面的资源，医院有其他的产品能获取到，客户的问题基本就是：我发烧了，难受，怎么办？怎么治疗？能不能帮我预约医生？怎么挂号等等问题针对客户的问题我们梳理了业务线，提前预约号，来医院挂号后寻找科室，和医生描述症状，医生告诉去检查，检查完回来医生确诊，吃什么药，怎么恢复，是否住院，买哪个药？根据这些问的描述我们抽象出以下本体包括：症状，疾病，科室，药品，食物，药企，检查，急救措施
根据我们的业务场景
```

#### 3.数据来源

```
数据来源：三九健康网，寻医问药网，医院提供的数据 （最后入库的实体都是经过逐条审核的）
```

#### 4.评估的标准

```
评估的标准：
准确性， 数据质量和实际的数据一致
一致性，图谱里面不能有关系或者属性冲突
完整性，图谱覆盖要广，满足业务需求
时效性，及时更新图谱，保证都是最近的数据信息
```

#### 5.如何构建一个schema框架

```
schema是构建知识图谱的一个框架，它是由本体关系属性三部分构成，我们搭建schema是通过具体的业务需求搭建的，也可以参考现有的一个schema，例如ULM医学框架，构建这个schema还是需要找出我们所需要的哪些实体，关系，属性，根据我们自己的业务需求找出自己需要哪些实体，关系，属性，通过遍历实体的形式，找出哪些关系是我们需要的，需要的进行一个保留，不需要的直接舍弃，属性也是将有用的保存到schema中，没用的进行一个舍弃。数据存的时候就会用到schema
```

#### 6.本体，关系，属性是如何构建的

```
关系：用遍历的形式来做的
属性选择：对图谱有用的属性我们保留：比如：传染方式，治疗方式，易感人群，患病比例，治疗费用 等
关系 实体 属性 我们做好了 ，经前馈神经网络，是一种最简单的神经网络，各神经元分层排列，每个神经元只与前一层的神经元相连。接收前一层的输出，并输出给下一层，各层间没有反馈。是应用最广泛、发展最迅速的人工神经网络之一过人工审核我们入库。

图谱数据量：  25万
症状：37000
疾病：43000
科室：60个
药企：5000个
食物：5000
药品：15万
检查：3000
急救措施：26

关系
一个疾病与另一个疾病之间的关系（伴随关系）:acompany_with

一个科室与另一个科室之间的关系（属于关系）:belongs_to

一个疾病与一个或多个治疗科室之间的关系（治疗科室关系）:cure_department

一个疾病与一种或多种食物之间的关系 (宜吃关系）:do_eat

一个疾病与一种或多种常用药物之间的关系（通用药品关系）:has_common_drug

一个疾病与一个或多个症状之间的关系(具有症状关系):has_symptom

一个疾病与一种或多种检查项目之间的关系(需要检查关系):need_check

一个疾病与一种或多种食物之间的关系(忌吃关系):not_eat

一个药企与一种或多种药物之间的关系(生产关系):production

一个疾病与一种或多种常用的或推荐的药物之间的关系(热门药品关系):recommand_drug

一个疾病与一种或多种推荐的食谱之间的关系(推荐食谱关系):ecommand_recipes

属性
cause（病因）：描述疾病可能的成因或原因，即导致疾病发生的因素。

cure_department（治疗科室）：指示哪个医疗科室或部门通常负责治疗特定的疾病。

cure_lasttime（治疗持续时间）：表示治疗特定疾病通常需要的时间段，包括疾病的疗程或治疗期限。

cure_way（治疗方式）：描述治疗特定疾病时采用的治疗方法或治疗策略，包括药物治疗、手术、康复等。

cured_prob（治愈概率）：表示患者治疗特定疾病后成功康复或治愈的概率或可能性。

desc（描述）：提供了关于特定疾病的详细描述、病情特征、症状和其他相关信息的文本描述。

easy_get（易感人群）：指明哪些人群更容易患上特定疾病，通常包括易感人群的特征或相关因素。

get_prob（患病概率）：表示患者患上特定疾病的概率或可能性，通常与易感人群和其他因素相关。

name（名称）：疾病的名称或标识符，用于唯一标识和识别特定的疾病。

prevent（预防方法）：描述预防特定疾病的方法、建议或措施，以降低患病风险。

symptom（症状）：列出了与特定疾病相关的常见症状，有助于医生和患者识别和诊断疾病。
```



### 五.电子病历识别

#### 1.项目背景

```
我们的项目背景为了丰富医院的his数据库，病历信息入库储存，甲方要求：把病历上所有的信息返回给他们，疾病和症状上保留关系，返回一个json串。
```

#### 2.图片识别

```
图片识别：ppocr对规整的病历识别的不错，手写的病历不好（我们都是电子病历）,因为都是识别规整的病例对于手写的识别不是很好，ocr识别的原理是先对图片进行一个检测，先识别哪块有文字的位置，再识别文本框中到底是什么字。
```

#### 3.pdf识别

```
pdf识别主要用到了pdfMiner,当pdf中嵌套图片识别不出来就用到了fitz中的python库，它可以将图片给找出来，找出来之后再用ocr技术识别出来。
文本裁剪：正则表达式 （诊断结果那段问题，规则化的，裁剪出结果，为我们后面提取关系准备语料）
```

#### 4.文本纠错

```
文本纠错：1.所用到的技术是pycorrector技术，bert模型，输入是一个错误文本，输出是错误文本的位置以及正确纠错后的内容。2.规则+模型，规则有个词典：包括正确字和错误字词典，模型:bert  mask掉的当作错误字进行预测。
```

#### 5.三元组抽取

```
实体和关系（合作方有这方面的需求）：TPLINKER  ：握手协议 解决实体重叠的问题 原理：找实体边界， 用第一个实体头指向第2个实体的头，第1个实体的尾指向第2个实体的尾，第一个实体的头指向第一个实体的尾，第2个实体的头指向第2个实体的尾，用的是矩阵的形式来记录的。
我们的数据标注采用labelstudio工具标注的，标注的形式：实体类别 和关系类别都定义好，用标注工具直接标，数据量10000条，标注了10天，数据来源是合作方给的，名字要加密，病例编号对应上。
```

### 六.Langchain-chatpdf本地知识库的构建

#### 1.LangChain的含义

```
LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如 API 和数据库。
LangChain中的三个模型：LLM(大语言模型)，Chat Model(聊天模型)，Text Embedding Models(文本嵌入模型)
```

#### 2.六大模块

```
它由六大模块组成，分别是Models，Prompts，Indexes，Memory，Chains，Agents
	models模块：主要是实现对大语言模型，聊天模型和embedding模型的管理
	Prompts模块：主要是进行提示词模板的管理，通过写一些提示词，让大模型学会需要实现什么样的功能，输出什么样的结果。
	Indexes模块：主要实现的是文本加载，文本分割，向量库储存管理的功能
	Memory模块：主要是提供一个记忆功能，比如涉及到多轮对话时，可以通过这个模块实现多轮对话的功能。
	chains模块：就是把各个组件拼接在一起，共同实现一个任务。
	Agents模块：相当于一个代理人，管家的角色，你说出你的需求，它自行决定调用哪些工具来为你服务
	最简单的应用方式：先通过langchain的models模块连接到大语言模型，如OpenAI，再构造一个prompt模板，将你想查询的信息写入到prompt模板中，利用prompts模块的功能进行提示词管理，最后将它传入到大语言模型中，即可生成相对应的回答，
	我们还可以将它用flask等方式进行封装，通过修改prompt的内容来让大语言模型实现不同的任务需求，如分类任务，ner任务，关系抽取任务等。
	这样就可以简单的实现，将llm模型应用到实际项目中，进行一个端到端的简单开发应用。
```

#### 3.项目背景：

```
基于langchain的强大功能以及llm的迅速发展，公司希望可以构建自己的一个本地知识库，将公司大量的文献资料上传到知识库中，能够实现一个知识的快速检索和资料整理
```

#### 4.项目流程：

```
1.先连接自己训练好的大语言模型，chatglm2-6B
2.将知识文本传入到langchain中进行文本加载，文本分割，和文本向量化储存
3.将query传入到langchain中，进行文本加载及向量化处理
4.利用faiss将query向量和向量库中储存的知识进行相似度计算，匹配出最相似的几条文本，构造对应的prompt模板
5.将prompt传入到llm模型中，生成相应的回答
```

#### 5.模型选型：

```
选择的llm模型：chatGLM2-6B，因为公司的文件大部分都是中文的文献，还有少量的英文文献，所以选择了支持中英双语，且在中文上表现突出的chatGLM2-6B模型

选择的embedding模型：m3e-base，M3E是Moka Massive Mixed Embedding 的缩写，是一个开源的中文Embedding 模型，M3E 使用 hfl 实验室的 Roberta 系列模型进行训练，使用 in-batch负采样的对比学习的方式在句对数据集进行训练，在文本分类和文本检索的任务上超过了chatgpt的官方embedding模型；
还可以选择最近比较火的基于transformers模型训练的BGE embedding模型，它在各项指标上都是超越了M3E模型的。

支持的知识文件格式：md，pdf，csv，txt，doc，docs，ppt，json等


M3E和BGE介绍链接：https://zhuanlan.zhihu.com/p/658112595
```

#### 6.模型搭建过程：

##### llm模型的连接方式：

```
1.先将训练好的llm模型用huggingface的transformers框架进行本地部署，再用flask将大模型封装为API服务。
最后得到的模型参数个数如下：
		"chatglm2-6b": {
        	"local_model_path": 模型路径,
        	"api_base_url": 封装好的API地址, 
        	"api_key": "EMPTY"
2.再通过langchain中的models模块连接到本地模型。
代码如下：
	from langchain.chat_models import ChatOpenAI
			model = ChatOpenAI(
    	streaming=True,
    	verbose=True,
    	openai_api_key=对应llm模型的api_key,
    	openai_api_base=对应llm模型的api_base_url,
    	model_name=对应的llm模型名称
	)
```

#### 7.知识库构建：

```
1.文本加载：
利用langchain的非结构化文件加载模块（UnstructuredFileLoader）基本可以将大部分文件加载进来，有其他需求可以根据任务需求添加其他库进行文本加载
2.文本分割（Text Splitter）：
虽然langchain有自带的文本分割库（如：CharacterTextSplitter），但是它这个分割是按照文本长度（len方法）来进行分割，实际应用中可能会导致某句话的语义信息被分割成两部分，所以我们自己构造了一个文本分割的方法，以标点符号为分割点，全部替换为“\n”,以此来进行文本分割，这样每一行都是一句完整的话，同时也保证了每条文本的一个上下文顺序，方便后续我们构建文本块（text chunks）时，进行上下文选取。
3.文本块（text chunks）构造：
文本分割时，我们设置了一条文本的最大长度为100，这就导致进行相似度计算时，可能只匹配到一个标题，信息不完整，所以我们进行上下文选取来丰富匹配到文本信息，这里我们设置了文本块的最大长度为250。
4.文本向量化：
这里我们用了langchain已经封装好的huggingface的embedding模型框架进行模型加载，将选取好的文本块（text chunks）传入到embedding模型中，输出的向量传入到faiss中保存起来。
embedding模型调用方式如下：
		from langchain.embeddings.huggingface import HuggingFaceEmbeddings
		embeddings = HuggingFaceEmbeddings(model_name=模型路径,model_kwargs={'device': device})
```

#### 8.query向量化：

```
用相同的embedding模型将query向量化，传入到faiss中进行相似度计算。
```

#### 9.prompt构造：

```
用faiss从向量库中进行相似度匹配，这里可以选择知识库匹配的向量数量，和相似度阈值（0-1之间，通常设置在0.5左右）。
先将匹配出的向量转回文本的格式，作为已知信息：context，再将query的文本信息作为question，填充到写好的prompt模板中

模板样式如下：
	PROMPT_TEMPLATE = """【指令】根据已知信息，简洁和专业的来回答问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题”，不允许在答案中添加编造成分，答案请使用中文。 
【已知信息】{context} 
【问题】{question}"""
```

#### 10.llm生成回答：

```
通过langchain中的LLMChain库将构造好的prompt传入到连接完成的model中生成回答，连接方式如下：
	from langchain import LLMChain
	chain = LLMChain(prompt=chat_prompt, llm=model, verbose=True)
```

#### 11.项目难点：

```
1.单次传入知识库中的文本资料大小不能超过300M，解决方式：对文件进行切分为小于300M的小文件分开上传，也可以直接将文件上传到对应的知识库文件夹中
2.文本分割的逻辑需要继续优化，原因是构造文本块时，选取的上下文数量的不同，可能出现语义信息不完整或者有错误的语义信息传入的情况，导致大模型推理时有知识遗漏或匹配不正确的问题出现
3.读取表格数据，如果是纯数据的表格文件，对某个字段对应的数据进行快速检索时，会出现回答错误的情况，解决方式：1.对大模型数据进行微调，2.检查表格数据读取后的文本样式，针对性的调整文本分割和文本块构建的方式，调整代码
4.有时候可能会出现匹配信息不完整，或者信息遗漏的情况，解决方式，可以通过调整知识匹配数量和相似度阈值来改进生成的答案。

5.我是根据语义信息进行相似度进行匹配出，语义信息有可能出现语义信息不完整的情况，对于表格这种精确查找的来说通过语义相似度度进行匹配是不能很准确的查找出来，后续，我也考虑到了这种情况，对于图片的来说我们可以根据OCR技术来实现，对于表格数据可以通过langchain更新的库关键字检索形式来进行检索
```

#### 12.总结：

```
最后，本地知识库搭建完成了，公司有大约3W多个文件资料，大部分为pdf文件和doc文件，也有少量的md文件和excel文件，我们按照文件内容的不同，构建不同的知识库，大概分为了10个库，如财报信息库，里面存放的全部都是往年的财报信息文件，还有技术资料库，法律信息库，药品信息库等，每个知识库都是按照这种方式进行知识存储，我们这个知识库也是公司自用的，再具体的信息就是公司机密了，所以我也就不多透露了，以上就时我们做的整个项目内容。
```

Langchain-chatpdf本地知识库的构建精简版话术

```
项目背景：基于langchain的强大功能以及llm的迅速发展，公司内部也是希望可以构建公司自己的一个本地知识库，公司有大量的文献资料，能够实现对公司资料的一个快速查询和资料整理
项目流程：
1.先连接自己训练好的大语言模型，chatglm2-6B
2.将知识文本传入到langchain中进行文本加载，文本分割，和文本向量化储存
3.将query传入到langchain中，进行文本加载及向量化处理
4.利用faiss将query向量和向量库中储存的知识进行相似度计算，匹配出最相似的几条文本，构造对应的prompt模板
5.将prompt传入到llm模型中，生成相应的回答

支持的文件格式：md，pdf，csv，txt，doc，docs，ppt，json等
选择的embedding模型：m3e-base
选择的llm模型：chatGLM2-6B
相似度计算：faiss

项目难点：
#1.无法读取图片数据，解决方式：可以使用其他的OCR库来接入到项目中，如paddleOCR等
2.读取表格数据时，比如说纯数据的表格文件，可能出现回答错误的情况，解决方式：对大语言模型进行微调
3.单次传入知识库的文本资料大小不能超过300M，解决方式：1.将文件切分为小于300M的文件分开上传；2.直接将文件上传到对应的知识库文件夹中
4.文本分割的逻辑需要继续优化，主要是存在选取上下文来共同构建一条语义信息时，可能因为选取的上下文本数较少，导致出现语义信息不完整的情况
```



# 九.自我介绍

```
第一块
面试官你好，我叫李鹏举，来自山西，本科学历，计算机科学与技术，目前处于离职状态。
第二块
我在上一家公司主要担任的是NLP算法工程师这样一个职务。
我在上一家公司工作的主要内容是：
第二是数据处理相关工作，第三是模型的选型及训练，第四是模型优化相关工作，第五是项目联调和部署相关工作。
第三块
我做过的项目有：
第一个是Sime  电子病历识别
第二个是Sammy  /ˈsæmi/百科问答机器人
第三个是Depew   /dɪˈpjuː/ 数字人诊断助手
第四个是Dukat大语言模型训练
第五个自动化评价系统
第六个是DiPu知识库的构建

第一个sime电子病历识别这个项目，主要是帮医院那边丰富他们的his数据库，因为他们给我们的数据都是图片或者pdf格式，我们要做的就是把图片或者pdf中的全部内容提取出来，然后返回给医院那边，医院把这些信息存到自己的数据库中

五：电子病历识别
合作医院要推进智慧医疗的建设，搭建对病历的OCR病历识别系统，可以有效减少人工成本，提升业务办理效率，
电子病历我们设置了两种识别方式，PDF和图片
如果是PDF文件，我们使用pdfminer+fitz 对 pdf 文件进行文字识别。
如果是图片文件，我们使用paddleOCR 对图片文件进行文字识别
识别完成后使用正则模板根据需求对结果进行文本剪裁。
然后用pycorrector进行文本纠错。
使用 tplinker 对症状、疾病和他们的关系进行三元组抽取,并将数据存入 mysql 数据库。
使用 fastapi 进行部署。

第二个项目是sammy百科问答机器人，这个项目我们主要是给医院做的，可以帮助医院解决一些咨询上的问题，帮助医生快速问诊，这个项目我主要做的就是知识图谱构建这块，我独立负责，从0到1搭建起来，也比较复杂，线上部分也是一个实时的问答系统，主要用到了意图识别，这里包括大意图识别，小意图识别，其他还有命名实体识别技术，置信度判断模块，还有模板回复模块。

四 ： 百科问答
这个项目我们主要是给医院做的，主要用来帮助患者解答基础的医疗问题，缓解医院就诊压力的
1.根据业务流程，构建schema，确定实体，关系，属性
2.根据schema，完成数据处理，传入到neo4j数据库
3，搭建线上知识问答系统，通过集成学习模型联合结果完成主意图分类功能；
4，使用 Roberta+textcnn 完成子意图分类；
5，设计并构建语义槽，使用规则和 bert+bilstm+crf 针对实体进行抽取并存入槽位；
6，通过置信度判断并选择回复策略，使用实体链接完成知识查询；

第三个项目depew数字人诊断助手，介绍 2部分(线上，线下)（每个部分是做什么） 再分别介绍每个部分有几个模块。
这个项目是和丁香公司那边一起做的，这个项目是在疫情期间做的，当时疫情很严重，属于封控阶段，在家去不了医院， 去医院也容易造成交叉感染，我们这个数字医生其实是一个辅助医疗诊疗机器人，它可以帮助医生辅助诊断客户患有哪些疾病。这个项目的结构主要分为线上和线下两个部分，而且这个项目比较复杂，线上部分主要是一个问答的系统，线下主要是一个知识图谱的构建，这个项目里主要有几个模块，其中线下部分有命名实体识别模块，还有命名实体审核，还有知识融合模块，还有存储neo4j数据库这样一个模块，而线上部分有主题相关模型这样一个模块，还有一个实体链接的模块，还有主逻辑服务这一个模块，再加上一个拓传的模块。这个就是第一个项目。这个项目中难点和优化点挺多的，尤其是闲聊模块我们后来用的大语言模型来做的，细节和坑也不少，如果面试官感兴趣自我介绍完我可以给你展开说一下。

数字医生：
其中第一个项目数字医生，这个项目是因为之前疫情期间的时候，人们都封控在家，线下就诊不方便，还害怕感染，所以为了解决这个问题，我们启动了一个可以进行线上问诊的数字医生项目，这个项目是和丁香公司那边一起做的，它分为了线上和线下两部分，线下部分主要是一个知识图谱的构建，线上部分提供了一个线上问诊的功能，知识图谱构建这部分分为了命名实体识别，命名实体审核，知识融合和neo4j数据库的构建这几个模块，线下部分分为了意图识别，句子主题相关模型，ac自动机，实体连接，主逻辑服务，闲聊机器人几个模块，
这个项目中的难点和优化点挺多的，尤其是闲聊模块我们后来用的是大语言模型来做的，细节和坑也不少，如果面试官感兴趣，自我介绍完，我可以给你展开说一下。

第四个项目是Dukat大语言模型，大语言模型这个项目背景，其实我们当时做这个模型主要是我们公司想拉融资，想训练一个我们公司自己的大模型，这个大语言模型是从0到1做的，我们三个人一块做的，这个项目最终也交差了，这个项目难点在于开源数据的清洗，还有就是训练中碰到的各种坑，第一步要做的是开源数据的清洗，第二是无监督形式训练一个语言模型，第三是进行一个有监督微调，第四是做一个基于人类反馈的强化学习(RLHF)，第五是使用PPO策略来进行一个参数的更新。

大语言模型
这个项目是在34月份llm火起来的时候，我们公司老板想做自己的大模型，然后取拉融资的，这个大模型的搭建我们是参考了chatGPT的那几步来做的，首先是数据的清洗，然后用清洗后的无监督语料训练一个有回复能力的大模型，第三步是用训练好的大模型进行一个有监督的微调，让大模型向着人类想要的方向回答，第四步是进行基于人类反馈的强化学习，设置一个奖励模型，对微调好的大模型生成的prompt的答案进行一个打分排序，这里我们用到了PPO的策略进行了优化训练，
这个项目我们是三个人做的，因为数据处理这块一个人做不来的，包括数据清洗，和有监督数据的筛选，工作量是很大的，模型训练，模型微调，还有强化学习这部分是我负责的，这个项目最终也交差了。

其中大语言模型的评价我们用的是自己搭建的评价系统， 可以从连贯性 信息量  流利性 几个维度判断模型的回复能力

这个项目的难点就在于开源数据的清洗，还有就是训练时碰到的各种坑，如果面试官感兴趣，一会可以展开说一下。

第五个项目是自动化评价系统
大语言模型的评价我们用的是自己搭建的评价系统，可以从连贯性 信息量  流利性 是否符合事实 几个维度判断模型的回复能力，自动化评价这个项目难点在于标注规则的定义，我们做这个是参考了两篇论文，同时参考了美团的冠军方案，来做的这样一个自动化评价系统，做这个项目主要是为了替代人工评估。具体细节稍后可以展开给你介绍一个。

还有就是dipu知识库的构建，这是我们公司自己的需求，因为我们公司有许多pdf这样的数据，比如说医疗文献这种，有很多这样的资料，就想构建一个自己的知识库进行快速检索。通过这个系统可以进行文献终的内容提问快读得到答案。

三：chatPDF
我们这个项目主要是公司自用的，因为现在大模型很火，还出现了langchain这个功能强大的部署框架，我们可以将这两个技术结合起来构建一个强大的本地知识库，公司里有很多的资料，这个系统搭建起来以后，我们就可以把资料传到知识库中，进行一个知识的快速检索。
这个项目的流程是这样的：1.用langchain链接一个大模型，2.将资料文件传入到langchang中进行文本加载，分割，重构，和向量化储存，3.将问题传入langchain中进行向量化表示，并用faiss进行一个知识匹配，4.将问题和匹配到的知识构造成一个prompt，传入到llm中，5.让llm生成答案，进行回复

二：自动化评价
我们做这个系统的目的：首先是因为人工评估太耗时耗力，我们想通过模型的方式来做，替代人工评估，另外一个原因就是我们可以通过自动化评价系统，从海量的语料中挑选出优质的对话语料，构建自己的语料库。

我们从连贯性，信息量，流利度几个维度进行分别建模，采用加权求和打分的方式，最后的分数代表了模型的回复在这几个维度的表现，分值越高，数据越优质。

这个项目的难点在于数据标注规则的定义，我们也是做了很多资料的调研，参考了几篇论文，具体细节可以一会展开给你介绍一下。

以上就是我做的项目，其中数字医生  大语言模型，知识图谱遇到的坑和优化还是比较多的，看看面试官你想了解哪一块，我给你细说一下！

我做过的项目有：1.数字医生，2.FXYL大语言模型，3.知识百科问答机器人（我主要做的是知识图谱构建这块，这部分是我独立负责从0-1搭建起来的，也比较复杂），4.自动化评价系统，5.电子病历识别，6.chatpdf知识库的构建（公司有自己的医疗文献还有资料，想构建一个知识库库快速检索，通过这个系统可以进行文献中的内容提问，快读得到答案）等，其中数字医生 大语言模型 知识图谱遇到的坑和优化还是比较多的，看看面试官你想了解哪一块，我给你细说一下！
```



# 十.面试题汇总  

##### 1.Simcse是如何训练的，如何评估的？

```
答：simcse是训练一个编码器，给定一个文本输出一个向量，它是用来做语义相似度的。第一语义相似度先转成语义的向量表示，第二计算这两个向量之间的相似度，语义相似度计算的常见的方式是余弦相似度的一个方式。它有两种训练方式一种是有监督的训练方式，有监督训练方式需要人工构建的把一条文本通过数据增强的方式给它构建成一个相似的样本，正样本构造的方式是随机位置插入符号，负样本是随机找一个给它配制成负样本。一种是无监督的训练方式，负样本是在同一批次每条样本和其它样本构建成负例，正例用到了bert随机mask,把这句话送入到bert两次因为用到了随机mask这样就会生成两个向量。simcse它遵循一个原理尽可能在训练的时候拉近与正样本的距离，让负样本保持均匀分布。我们simcse没有用到评估，我们只是在我们语料上进行了两轮训练，让它可以有语义表达就行了，我们真正做语义评估是在做相似度计算的时候，通过人工进行评估。
```

##### 2.PPO策略，它的策略优化是怎么做的？

```
答：PPO （proximal policy optimization，PPO）近端策略优化，核心思想是限制策略更新幅度，以达到稳定、高效的训练结果。
PPO 算法之所以被提出，根本原因在于 Policy Gradient（策略梯度） 在处理连续动作空间时 Learning rate 取值抉择困难。Learning rate 取值过小，就会导致深度强化学习收敛性较差，陷入完不成训练的局面，取值过大则导致新旧策略迭代时数据不一致，造成学习波动较大或局部震荡。除此之外，Policy Gradient 因为在线学习的性质，进行迭代策略时原先的采样数据无法被重复利用，每次迭代都需要重新采样。
具体来说，PPO算法使用了两个损失函数：第一个损失函数是近端比率裁剪损失，用于限制策略更新幅度；第二个损失函数是价值函数损失，用于优化策略。两个损失函数的加权和就是PPO算法的总损失函数。
```

##### 3.langchain,

```
答：LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如 API 和数据库。
```

##### glm

```
原理：
​           基于自回归空格填充方法，结合了bert、gpt、T5预训练模型的思想
​			输入：
​					输入由两部分构成，PartA是mask后的文本序列,Part2是mask跨度的打乱的词，开始用S，结束用E
​					采用二维位置编码第一个位置id用来标记Part A中的位置，第二个位置id用来表示跨度内部的相对位置，embedding后都会被加入	到输入token的embedding表达中
​			结构：
​           		重组了层次归一化和残差连接的顺序；
​          		 使用单个线性层对输出token进行预测；
​          		 激活函数从ReLU换成了GeLUS
​          		 Part A中的tokens彼此可见，但是不可见B中的任意token
```

##### 4.Chatglm和llama模型的区别？

```
答：chatglm和llama的区别：

训练语料方面：chatglm支持中英双语，而llama训练的的中文的语料只有0.13%，英文语料有89.7%，对英文很友好

训练方式上，chatglm只进行了预训练和SHF阶段并辅助以RLHF，llama进行预训练、有监督微调（SHF）、基于人类反馈强化学习（RLHF）阶段，其中RLHF阶段训练了两个奖励模型分别在有用性和安全性更加符合人类偏好，使用拒绝采样和PPO算法

模型结构方面：chatglm使用的glm框架，而llama相对于transformer架构做了以下改动

1. 前置的均值归一下(RMSNorm)，不在使用层次归一化（layernorm）,将RMSNorm前置让训练会更加稳定。
2. 在Q、K上使用旋转式位置编码，token长度具有更好的外延效果。。
3. 线性层不使用relu激活函数，使用silu激活函数。
4. 使用了(GQA)Group Query Attention，多个查询头关注相同的键和值头，减少推理过程中 KV 缓存的大小，并可以显著提高推理吞吐量。

如果我们微调中文模型可以选择chatglm,如果是英文模型我们可以选择llama
```

##### 5.文本纠错:梦创双标总部在上海进行，纠错改成梦创双样

```
答：我们做文本纠错所用到的技术是pycorrector技术，用到的模型是bert模型，它的原理是输入是一个错误文本，输出是错误文本的位置以及正确纠错后的内容。但他的准确率不是那么高，后来我们采用大语言模型来做文本纠错，给定的模板如下你先给定大语言模型一个身份，我现在要做一个文本纠错的任务，我的样本如下请帮我进行一个纠错，回答的时候纠错后的结果如下这样的文本对给到模型，训练的时候语料要有不一样的，如何改正确文本同义词替换，同名字替换，将字变成错字，我们有nlp工具可以找出来，我们训练语料有10000条，我们评估的形式通过错误的正确的进行比对，比方说有100条数据有十条错误的，错误率为10%。
```

##### 6.讲解一下什么是embedding 

```
答：embedding是把一个词变成一个向量，我们常见embedding形式bert,word2vec，还有我们最开始使用的one-hot编码，bert与word2vec的一个区别是，bert是一个动态的训练方式，她训练的embedding在不同的场景下有不同的语义表达，而word2vec是一个静态的她训练的embedding在一个的场景一个的语义表达，换个场景表达的意思就不对了，word2vec它的两种训练模型，一个是skip gram 一个是cbow这两种模型Skip-gram是用中心词去预测周边词，CBOW是通过上下文来预测中心词，他还有两种加速方式一个是负采样一个是层次softmax
负采样的思想是针对正样本的单词向量进行更新，对于负样本，采样出一部分进行更新。层次softmax它的一个思想是将多分类问题转化成多个二分类问题。embedding在我们使用模型初始的时候用到，因为模型不懂文字，需要将文字转成向量最后转成张量传入到模型里。
```

##### 7.模型是怎么微调的

```
答：微调在我们做第一个项目中有体现 我们最开始选用的闲聊机器人是GPT2，自己训练的，找的开源语料清洗质量不是很好，找别人做的，它支持3轮对话，在信息量这个维度上表现的不咋好，我们合作方有些优质的语料，小艺的语料有400万。今年我们用大语言模型微调来做的效果还是蛮不错的。我们后来选用chatglm2模型，这块我们做了很多工作，我们这个模型是为了完成2个任务，第一，具有闲聊能力，第二，如果数据库没有查询到疾病或者特殊问题，启动语言模型对疾病进行回答，所有我们用了少量的医疗问答做了微调，让模型又能闲聊又能回复疾病。因为大语言模型毕竟是生成模型，不能确保回答的都是正确的，所以我们优先走检索式，用生成式兜底，语料我们爬取39健康网，经过清洗一共5万条，训练的时候进行了不同层级对比训练，1万-5万分别测试，训练轮次1000-5000分别测试，最终法向，2000轮次5万数据效果最好。但是在我们训练过程中也碰到到了一些问题，第一出现回复重复问题，经过测试，是训练轮次不足导致的，后来加大训练轮次就解决了，第二丧失了闲聊功能，解决方案后来加入了闲聊语料来解决，我们加入了不同的配比的闲聊语料，5%，10%，15%，20%跨度进行训练，最终得出的结论，15%的闲聊配比，2000轮次，5万数据效果最好。同时我们也对比了baichuan-7b(百川),qianwen-7b(阿里),internlm-7b(上海研究院)都是打榜比较靠前的模型，从回答长度，模型使用量来评测，还是chatglm2效果好。
```

##### 8.什么是schema

```
答：是构建知识图谱的一个框架，它是由本体关系属性三部分构成，我们搭建schema是通过具体的业务需求搭建的，也可以参考现有的一个schema，例如ULM医学框架，构建这个schema还是需要找出我们所需要的哪些实体，关系，属性，根据我们自己的业务需求找出自己需要哪些实体，关系，属性，通过遍历实体的形式，找出哪些关系是我们需要的，需要的进行一个保留，不需要的直接舍弃，属性也是将有用的保存到schema中，没用的进行一个舍弃。数据存的时候就会用到schema。
```

##### 9.主意图识别是怎么做的，分别有哪些意图，主意图识别用到了哪些模型？

```
答：
答：大意图分类（6类意图分类）：接受意图（客户对机器人的回复表示肯定），诊断意图（和疾病症状相关的意图），打招呼意图，结束意图，机器人意图，否认意图（表示否认的语言回复）数据量有24000条，比例是1:1,数据来源是合作方给的一部分数据还有一些是开源的数据还有些是通过数据增强的方式生成的，用到的模型是模板匹配+tinnybert+rnn，准确率达到98%   
分别有哪些意图：我们这个项目里用到了大意图分类（6分类），小分类意图（13分类）
大意图分类（6分类）包括：接受意图（客户对机器人的回复表示肯定），诊断意图（和疾病症状相关的意图），打招呼意图，结束意图，机器人意图，否认意图（表示否认的语言回复）
小分类意图（13分类）包括：疾病的定义，疾病的病因，疾病的症状，并发症，治疗方法，所属科室，传染性等等
```

##### 10.为什么要使用投票机制？如果三个模型指向三个意图该如何处理？

```
答：因为单单使用一个模型的话不一定准，当使用单个模型不准的情况下，使用多个模型会对其进行一个补充。
当出现三个模型指向三个意图我们会根据准确率高的权重越高，我们会选择权重更高的内个。
```

##### 11.命名实体识别是怎么做的，使用了什么模型，怎样标注的，效果怎样

```
答：
```

##### 12.说一下F1，召回率，精确率，准确率的公式

```
TP（True Positives)：真正例，预测为正例而且实际上也是正例；

FP（False Positives)：假正例，预测为正例然而实际上却是负例；

FN（false Negatives)：假负例，预测为负例然而实际上却是正例；

TN（True Negatives)：真负例，预测为负例而且实际上也是负例。
召回率=TP/（TP+FN）  

精准率=TP/（FP+TP） 

F1 = 2*（召回率*精准率）/（精准率+召回率）

准确率 = （TP+TN)/(TP+TN+FP+FN)
```

##### 13.faiss是干啥的，在哪块用到的，是怎么使用的？

```
答：faiss是用来做语义相似度计算的工具，它里面嵌套了各种计算方式，它主要是query和候选的计算查找速度特别快，我们使用的时候先是将所有的文本转成向量传到faiss中，在拿出一个query和他进行一个计算，计算的选择方式有很多，但是没有余弦相似度，我们用到的是点积的方式，分值越高说明越相似，在我们项目中实体审核和知识融合用到了faiss,它的计算方式是，先用simcse训练出自己的一个编码器，然后把所有的候选值用simcse进行一个编码，存入到faiss里，在拿出一个query先拿simcse转化成向量，然后在faiss里面进行查询，最后分值越高当作我们最优返回。
```

##### 14.说一下大语言模型项目，当时训练大语言模型用了几张显卡，为什么没有上线？

```
答：算力 多机多卡 A100 80G 4张，单机单卡A100 80G 1张，4090 24G 8张，训练时常是480多个小时，3000w数据。我们这个项目已经完成交付任务了，我们在三个维度上表现的很好在连贯性，流利度，信息量量上表现很好，但是在是否符合事实，迷幻性上表现不是很好，是否符合事实需要大量的语料我们一下收集不到大量的数据，还有迷幻性在业界都是通用的难题，没有很好的多轮语料，这个我们也一下解决不了。
```

##### 15.介绍一下开发大语言模型的时候遇到的哪些问题，如何解决的

```
第一个问题是：代码有bug导致训练作废，
第二个问题是在训练的时候loss不稳定，反复去调整超参数，
第三个问题是发现超参数有不少尖峰（loss异常）最后还换了激活函数将Gelu换成Relu，
第四个问题GPU掉线等硬件问题，CUDA错误，任务挂起，NCCL错误，代码bug,训练不稳定再次发生。

大模型推理速度慢如何解决：流式输出，提高硬件显存提高
```

##### 16.说一下transformer，为什么要使用根号dk？

```
答：防止qk的值过大，在经过softmax时数据集中于0，或者1
```

##### 17.bert为什么用层次归一化而不用批次归一化？

```
答：批次归一化是不同样本在同一纬度做归一化，层次归一化：同一样本在不同维度进行归一化。我们在这里用到了层次归一化。单独考虑一个维度是没有意义的，综合考虑所有维度才有意义。
```

##### 18.大模型上线了吗？

```
答：我们训练的大模型已经达到标准了，拿着去拉融资了，我们这个大模型在两个维度上面表现的还不是很好，一个是在是否符合事实这个维度上，一个是在迷幻性这个维度上面，在是否符合事实这个维度上我们的数据没有很多，还有就是在迷幻性这个维度上这个是业内公认的一个难题，这个我们也没解决掉，因为它需要多轮对话的一个训练能力，这个我们目前只支持三轮对话，超过三轮效果就不是很好了。
```

##### 19.强化学习和梯度下降相似吗？

```
答：强化学习：强化学习其实是一个自主学习的一个过程，他在学习的过程中需要两个元素分别是环境和智能体，它是智能体先通过学习给环境一个反馈，然后环境根据他给的反馈进行一个打分，不断进行反馈，不断进行打分直到分数很高说明强化学习已经学习的差不多了，我们一版会使用ppo策略将参数进行一个更新保存。
梯度下降：输入数据经过sigmoid(wx+b)得到下一个神经元的输入，下一个神经元的输入在经过sigmoid(wx+b)得到下一个神经元的输入，以此类推直到最后一层得到预测值，得到预测之以后前向传播这块就算完成了，根据预先提供的真实值通过公式计算真实值与预测值之间的误差，通过反向传播依次向前传递误差，不断调整误差通过前向传播计算误差值与真实的差距，直到误差值接近真实值之后就完成了。然后保存调整好的权重与偏置。
```

##### 20.不能上线的主要瓶颈是什么？

```
答：在两个维度上面表现的还不是很好，一个是在是否符合事实这个维度上，一个是在迷幻性这个维度上面，在是否符合事实这个维度上我们的数据没有很多，还有就是在迷幻性这个维度上这个是业内公认的一个难题，这个我们也没解决掉，因为它需要多轮对话的一个训练能力，这个我们目前只支持三轮对话，超过三轮效果就会胡说八道，如果这样的一个产品上线了会有不少的投诉。目前我们也没有很好的一个方案来处理。
```

##### 21.为什么要从零开始而不是直接使用别人的预训练模型？

```
答：随着大模型的兴起，我们公司想通过大模型来拉融资，如果直接使用别人的成果会侵权的。
```

##### 22.预训练模型时间，数据量是多少？

```
答：预训练模型的时间也没咋统计大概是三天左右，全部训练完480个小时，我们的数据来自于悟道:7300w，悟道数据5900w,github开源数据 1400w,书生万卷1T
悟道：200G 5900w
维基百科：100w
百科问答：150w
社区问答：410w
翻译语料 520w
书生万卷 2T文本1T图像视频1T
清洗后的数据是3000w数据
```

##### 23.开源数据清洗？

```
开源数据清洗：
基于规则的噪音过滤：
1、删除在对话中的平台标签
2、从网址字符串中删除文本
3、对话数超过30的会话拆分为多轮对话数少于30的会话
4、在一个句子中仅保留重复超过6次的短语或单词
5、如果回答太长或太短，则删除对话
6、如果识别为广告则移除对话
7、如果回复中90％的三元组是高频三元组，则删除对话
8、如果回复具有某些特定形式的通用回复，则删除对话
9、删除回复与帖子相同的对话
10、脏话，敏感词和方言
11、有专业术语
12、名称，称谓和未知缩写
13、特殊符号和表情符号
14、平台标志，例如与广告，图片和视频相关的单词
基于分类器的过滤：
15、回复不流畅或句子中有严重错别字
16、回复的信息不完整
17、对话的主题是有时效性的
18、帖子中未提及的节日，地点，性别和时间出现在回复中
19、帖子和回复无关
```

##### 24.数据处理这方面是你做的吗？

```
答：数据是我们三个人一起做的，一个做不完，数据总量70000多万条，经过我们20多种数据清洗的方式最后就剩下30000万条数据。
```

##### 25.数据来源和处理的流程说一下？

```
答：数据来源数据5900w,github开源数据 1400w,书生万卷1T
悟道：200G 5900w
维基百科：100w
百科问答：150w
社区问答：410w
翻译语料 520w
书生万卷 2T文本1T图像视频1T
清洗后的数据是3000w数据
数据处理的流程：数据是我们三个人一起做的，一个做不完，数据总量70000多万条，经过我们20多种数据清洗的方式最后就剩下30000万条数据。
```

##### 26.悟道是啥？

```
答：悟道是一个数据集，它里面有200G数据其中每一个数据集中有多个文件，都是以json的形式进行一个保存，它包括了id,类别，标题，无监督语料，这个数据不能拿来直接用，其中有部分噪音数据但很少需要我们进行一个清洗才可以使用，悟道数据是我们大模型数据的主要来源。
```

##### 27.实体，关系有哪些类型，数量有多少，实体识别的标签有哪些？

```
答：
答：实体识别标签B,I,O -标签有多少个类别就有多少个标签
```

##### 28.用户的输入是千奇百怪的，怎么通过这些症状找疾病？

```
答：我们根据用户的输入我们有ac自动机来提取症状，如果提取到了症状就会根据症状去neo4j去查询疾病，如果提取不到症状就会启动追问模板，我们的模板只会追问两次，如果还是没有就会启动闲聊机器人进行一个回复。
```

##### 29.deepspeed框架？

```
Deepspeed是一个分布式训练框架可以大大提高训练效率，节省时间和成本。

该框架采用多种技术手段来加速训练，包括使用梯度累积来提高批量大小，从而提高训练效率。

还使用了ZeRO内存优化技术用于提高显存效率和计算效率。ZeRO可以克服数据并行和模型并行的局限性，同时实现两者的优点，使用动态通信调度来在分布式设备之间共享必要的状态，将模型状态和梯度进行分区以节省大量内存，还可以利用CPU和GPU内存来训练大型模型。

总之，deepspeed框架训练大模型可以减少训练内存占用、减少了分布式训练期间的通信量、支持长序列，可以快速收敛以加速训练提高效率。
```

##### 30.大语言模型到6月，是有啥变动吗？

```
答：正常到六月要发绩效，感觉有点不对劲，我跟hr关系挺好的他和我说能找机会就找找机会，我明白他说的意思了，然后就离职了。
```

##### 31.讲一下最近的这个项目（大模型）完成了哪些工作，负责哪些模块？

```
答：大语言模型背景，四步如何做的，重点说数据清洗，项目碰到哪些难题
```

##### 32.你们的数据大部分是公开获取的，chatglm已经做这些工作了，你们做的时候有没有深入做领域，你们做这个工作的意义是什么？

```
答：我们最开始选用的闲聊机器人是GPT2，自己训练的，找的开源语料清洗质量不是很好，找别人做的，它支持3轮对话，在信息量这个维度上表现的不咋好，我们合作方有些优质的语料，小艺的语料有400万。今年我们用大语言模型微调来做的效果还是蛮不错的。我们后来选用chatglm2模型，这块我们做了很多工作，我们这个模型是为了完成2个任务，第一，具有闲聊能力，第二，如果数据库没有查询到疾病或者特殊问题，启动语言模型对疾病进行回答，所有我们用了少量的医疗问答做了微调，让模型又能闲聊又能回复疾病。因为大语言模型毕竟是生成模型，不能确保回答的都是正确的，所以我们优先走检索式，用生成式兜底，语料我们爬取39健康网，经过清洗一共5万条，训练的时候进行了不同层级对比训练，1万-5万分别测试，训练轮次1000-5000分别测试，最终法向，2000轮次5万数据效果最好。但是在我们训练过程中也碰到到了一些问题，第一出现回复重复问题，经过测试，是训练轮次不足导致的，后来加大训练轮次就解决了，第二丧失了闲聊功能，解决方案后来加入了闲聊语料来解决，我们加入了不同的配比的闲聊语料，5%，10%，15%，20%跨度进行训练，最终得出的结论，15%的闲聊配比，2000轮次，5万数据效果最好。同时我们也对比了baichuan-7b(百川),qianwen-7b(阿里),internlm-7b(上海研究院)都是打榜比较靠前的模型，从回答长度，模型使用量来评测，还是chatglm2效果好。
意义是：我们自己做这个工作的意义是为了通过这个大语言模型来拉融资，如果使用其他人的模型涉及到了侵权。
```

##### 33.你们在做训练的时候，每个阶段大概用到了多少资源？

```
答：第一步先训练一个无监督语言模型，我们有八张卡算力特别充足，第一步无监督大概是200个G一张A100两张4090，总体来说用了360个G的资源，因为我们训练批次比较大，算力也够用用了100小时左右。
```

##### 34.你们整个项目是在deepspeed上连着做是吧？

```
答：是的，Deepspeed是一个分布式训练框架可以大大提高训练效率，节省时间和成本。

该框架采用多种技术手段来加速训练，包括使用梯度累积来提高批量大小，从而提高训练效率。

还使用了ZeRO内存优化技术用于提高显存效率和计算效率。ZeRO可以克服数据并行和模型并行的局限性，
同时实现两者的优点，使用动态通信调度来在分布式设备之间共享必要的状态，将模型状态和梯度进行分区以节省大量内存，
还可以利用CPU和GPU内存来训练大型模型。

总之，deepspeed框架训练大模型可以减少训练内存占用、减少了分布式训练期间的通信量、支持长序列，可以快速收敛以加速训练提高效率。
```

##### 35.glm做预训练和bert做预训练在模式上有什么区别？

```
答：glm做预训练
bert做预训练
对比区别：
```

##### 36.glm的输入有长度限制吗？

```
答：没有，一般都是2000，我查询过其他学者发表的在长度为2000
```

##### 37.那它截断是多长截断？

```
答：我们查询很多资料，长度在2000以内阈值最好。
```

##### 38.你们在做模型训练的时候是使用清华开源代码里的deepspeed还是你们自己做清华的glm在deepspeed上训练。

```
答：一般是使用清华的glm在deepspeed代码上训练，我们的代码里面有用到deepspeed
```

##### 39.奖励模型同一个问题得到4个回答，那么对于同一个模型来说，同样的输入得到答输出是一样的吗？

```

```

##### 40.第二阶段的数据格式是怎么样的？

```

```

##### 41.第三阶段的数据格式是怎么样的？

```

```

##### 42.使用三个维度进行评估这个模式是通用的吗？

```
答：通用的，当时我们定义打分规则的时候选用了三个维度上制定了一个打分规则，分别是连贯性，信息量，流利度上，下面我拿连贯性这个维度来讲述一下我们是如何在这个维度上定义的打分规则。0-0.6生成的文本几乎没有连贯性，句子之间的转换非常不流畅，难以理解。0.6-1.4生成的文本有一些连贯性，但存在明显的断裂或句子之间的转换不够自然流畅。
1.4-2.0生成的文本在结构和逻辑上连贯，句子之间的转换自然流畅.

定完三个人理解标注规则标注的数据样子是从开源数据中采集下来的它的数据样式是一个问题一个答案，在五个维度上连贯性，信息量，流利性，是否符合事实，迷幻（取3个人在不同维度的平均值）使用加权求和取平均值的方式，先是三个人在了解标注规则之后一个维度上取平均值，这样每个维度都有一个平均分，然后根据每个维度上都有各自的一个权重，平均分*权重相加再求和得到最终的一个打分，如果分数高说明在这五个维度上表现都很好说明是条优质语料。
```

##### 43.对模型你们有做人工评估吗？

```
答：多人标注：取平均值，最终采用加权求和的方式
维度选择：连贯性（第一句话和第二句话是否是连贯的），信息量（这句话信息足不足，包不包括很多信息量），流利性（符合正常人说话，没有语法错误，用词是否准确），是否符合事实，迷幻性（多轮对话回复是否胡说八道）
定义评估标注：0-2用的是连续性规则，0-0.5，0.5-1，1-1.5，1.5-2。
```

##### 44.做实体识别怎么把数据存到数据库里

```
答：通过sql语句进行一个存储
```

##### 45.知识融合是怎么做的？

```
答：将相似的疾病进行一个合并，合并后的症状进行合并去重(例 糖尿病1期，糖尿病2期)
我们先处理数据，我们模型选择的是simcse+faiss，先出了一版baseline，我们的数据量43000，我们是一个标注的用来一天的时间。正样本我们用的是simcse有监督的，正样本是两个相似的样本，负样本是两个不相似的，这块是对疾病进行融合，正样本要求两个相似的样本是很难的，我们也做过其它的一些方法，比如数据增强，把一个疾病增强变成一个相似的疾病，增强的方式有很多比方说加个噪音去个字，效果都不咋好，因为它改变了原有的语义，所以说我们最终用了标点隔断的方式，而负样本是将正样本进行一个倒序变成一个负样本了
正负样本比例是1:1的形式加起来总共是86000条。simcse是双塔模型主要是做相似度计算的他有两个训练形式一个是有监督的一个是无监督的，无监督是不需要标签的，直接一个疾病当作一个正样本，负样本是论文中提到的一个形式它把一句话送入到bert模型中两次用随机mask形式增强出一个embidding向量当作一个相似样本而负样本是与同一批次样本与其它的样本构成负样本，但事实证明无监督没有有监督训练的好。faiss是一个搜索工具，它主要用到了向量的内积，在评估这块我们主要用到了人工评估，大概有五六条不太好的数据，faiss的阈值是
```

##### 46.simcse是做句子相似度的，他在词相似度上效果好吗？

```
答：simcse是做语义相似度的，当一句话越长语义越明显，当在词上面做语义相似度，词越少的话模型学不会它的语义信息，所以在词上面做相似度计算效果不好。如过做词相似度我们有其它方法有编辑距离的方法也可以做。
```

##### 47.simcse是怎么做的无监督训练？

```
答：simcse是训练一个编码器，给定一个文本输出一个向量，它是用来做语义相似度的。第一语义相似度先转成语义的向量表示，第二计算这两个向量之间的相似度，语义相似度计算的常见的方式是余弦相似度的一个方式。它有两种训练方式一种是有监督的训练方式，有监督训练方式需要人工构建的把一条文本通过数据增强的方式给它构建成一个相似的样本，正样本构造的方式是随机位置插入符号，负样本是随机找一个给它配制成负样本。一种是无监督的训练方式，负样本是在同一批次每条样本和其它样本构建成负例，正例用到了bert随机mask,把这句话送入到bert两次因为用到了随机mask这样就会生成两个向量。simcse它遵循一个原理尽可能在训练的时候拉近与正样本的距离，让负样本保持均匀分布。我们simcse没有用到评估，我们只是在我们语料上进行了两轮训练，让它可以有语义表达就行了，我们真正做语义评估是在做相似度计算的时候，通过人工进行评估。
```

##### 48.项目是几个人做的，你主要负责哪些模块？

```
答：第一个项目找几个模块说一下。。。。。，第二个模块找几个模块说说
```

##### 49.智能医生是怎么做的，上线这块你了解吗？

```
答：我们采用分布式部署，我们一般有云端部署和本地部署，我们公司部署采用云端进行一个部署，不同的服务部署在不同的服务器上，我们租了六台服务器，我们闲聊这个模块要带GPU,部署的框架以接口的形式进行一个封装，supervison守护进程，还有就是并发量的问题，可以采用用到nginx负载均衡来缓解，对于并发量大的可以采用熔断机制，分布式缓存，分布分表来缓解。上线之前得做灰度测试（公测）
灰度测试涉及到的环境一个灰度测试的环境，开发环境，上线的生产环境
```

##### 50.对大语言模型有哪些理解？国内国外有哪些知名的大语言模型？

```

```

##### 51.大语言模型的微调方式有？

```
答：Fine-Tuning,Prompt-Tuning(p-Tuning),Prefix-Tuning,p-Tuning-v2,Lora,QLora,RLHF。
```

##### （1）Fine-Tuning：

```
答：属于全量参数微调，它就是将预训练模型与少量特定任务数据一起训练。多用于bert、gpt预训练模型微调
```

##### （2）Prompt-Tuning(p-Tuning)：

```
答：属于部分参数微调，它就是根据你的任务精心设计一个提示模板，通过bilstm+mlp进行一个编码，和我们的输入做一个拼接进行训练，训练的时候只训练模板编码的参数
```

##### （3）Prefix-Tuning：

```
答：属于部分参数微调，它就是直接在输入前添加一个任务特定的向量化序列，训练的时候只训练这部分参数
```

##### （4）p-Tuning-v2：

```
属于部分参数微调，它就是是在每一层都加入了Prompts tokens作为输入，训练的时候只训练这部分参数，用于ChatGLM微调
```

##### （5）Lora：

```
答：他用到了旁支矩阵加入了A和B两个结构，A的输入维度和B的输出维度分别与原数据的输入输出维度相同，A矩阵相当与做降维作用，B矩阵相当于将降维后的维度进行一个还原，最后在推理的时候将AB权重与原模型权重进行一个合并。
```

##### （6）QLora：

```
答：使用一种新颖的高精度技术将预训练模型量化为 4 bit，然后添加一小组可学习的低秩适配器权重，这些权重通过量化权重的反向传播梯度进行微调。它可以减少内存的使用，足以在单个48GB的GPU上微调65B的参数模型，同时保留完整的16位
```

```
10个v100，300G，利用率80%，10个卡，就是10ge卡，
```



##### （7）RLHF：

```
1、人工构建精良数据集对预训练模型进行微调（LM）

2、给微调后的模型一个prompt 生成3-4个答案，对答案进行排序，将回答对放到RW模型中进行打分训练生成一个奖励模型（RW）

3、用强化学习方法微调LM，使用PPO策略，解决学习率的取值问题，用来限制策略更新幅度，通过近端比例裁剪损失和价值损失之和来控制
```

##### 52.chatglm和llama的区别？

```
答：训练语料方面：chatglm支持中英双语，而llama训练的中文的语料只有0.13%，英文语料有89.7%，对英文很友好
在训练方式上：
模型结构方面上：归一化（均值归一化），位置编码（旋转位置编码），激活函数（relu-silu），注意力机制(Group Query Attention 减少推理过程中kv缓存大小，并可以提高吞吐量)
```

##### 53.项目组有多少人

```
答；项目组有7个人，两个算法，两个后端，两个标注，1个前端
```

##### 54.说一下逻辑回归

```
答：逻辑回归使一个二分类模型，它是在线性回归的基础上加入了一个激活函数sigmoid，表达式为：y = 1/(1+e-x)，它的取值范围是在0-1之间，大于0.5，判定类别为1，小于0.5，判定类别为0，如果数据量不大，且数据噪音小时，我们就可以用逻辑回归的模型来实现一个二分类的任务，跑一版baseline来看看效果。
```

##### 55.算力搭载了多少个GPU

```
答；我们一共用了一张A100，8张4090，总算力由360个G，模型训练需要350个G
```

##### 56.

```

```

##### 57.大语言模型数据如何收集整理的

```
答：开源数据：悟道，github开源数据。

悟道数据：它里面200g的数据，每个数据集有多个json文件，保存的有id，类别，标题，无监督语料，这个数据不能拿来直接使用，其中有部分数据是需要我们进行清洗才可以使用，悟道数据是我们大语言模型的来源。

清洗之后只剩下了三个标签，id，类别和字段 ，因为我们大语言模型训练的时候只需要id，类别和字段
```

##### 58.大语言模型数据类型

```
答：悟道，维基百科，新闻语料，百科问答，社区问答，翻译语料，书生万卷。
```

##### 59.大语言模型结构，参数量，算力

```
答：glm的框架，参数量用的是6b，算力用的是350g的显存完成的
```

##### 60.大语言模型的结果如何评估的

```
答：自动化评估，从迷幻性，连贯性，流畅性，信息量，是否符合事实五个维度进行的评估，是自己的评估
```

##### 61.大语言模型是否可以商用

```
答：我们的模型商用也可以用，但是效果没有达到完美的标准，因为在迷幻性和是否符合事实的维度上表现的还是不是很好，但是老板看到结果之后觉得ok了。
```

##### 62.装饰器是什么

```
答：装饰器是python编程语言中的高级功能，装饰器通常用于添加功能、包装函数或方法，或者进行日志记录、性能分析等操作。装饰器是Python中的一种元编程特性，允许你动态地修改或增强其他代码的行为。
```

##### 63.深拷贝和浅拷贝的区别

```
答：深拷贝的含义是：在深拷贝中，不仅复制外部对象，还会递归复制内部嵌套对象，创建全新的对象结构。这意味着原始对象和深拷贝对象之间没有共享引用。
浅拷贝的含义是：在浅拷贝中，只复制了数据结构的外层对象，而不递归复制内部嵌套对象。这意味着原始对象和浅拷贝对象之间共享内部嵌套对象的引用。
总结：浅拷贝和深拷贝的主要区别在于修改浅拷贝中的嵌套对象也会影响原始对象，而深拷贝中的嵌套对象是独立的。
```

##### 64.用过vim编辑器吗

```
答：用过，他vim是一种文本编辑器，可以用于linux系统文本编辑功能，vim有多种模式，包括插入模式，命令模式和可视模式。
```

##### 65.linux删除进程命令

```
答：kill PID
killall process_name（后面这个name是终止目标命令的名称） 也可以回答killall+进程名称
```

##### 66.linux筛选正在运行的python进程ps aux | grep python

```
答：pgrep命令可以直接查找包含指定名称的进程，并返回它们的PID。这将只返回Python进程的PID。
```

##### 67.随机森林可以做分类任务还是回归任务

```
答：随机森林可以做分类任务也可以做回归任务，它是由多棵树构成采取有放回的的形式抽取部分特征和数据样本来构建多棵树，它可以做分类任务也可以做回归任务，分类：投票，回归：取平均，适用场景噪音数据量不是很多的情况，可以出一版baseline。
```

##### 68.Xgboost如何构造的目标函数

```
答：XGBOOST是集成模型可以做分类任务也可以做回归任务，对残差进行拟合，首先先正常构建第一个树进行正常预测，接着第二颗树要对第一棵树的误差进行一个拟合，以此类推后面的树对前一棵树的误差不断拟合，直到误差为0或者足够小可以接受，构建完毕，它加入正则项，主要用到的是二阶泰勒求导，借助随机森林，对缺失值进行很好的处理。
```

##### 69.说一下lstm的结构

```
答：首先lstm是一个rnn的一种变体，专门设计用于处理长序列和解决串通rnn中的梯度消失问题，lstm拥有更强大的记忆能力，适用于各种序列数据，如文本、时间序列和语音，他有四个门，分别是输入门，遗忘门，更新门，输出门

输入门主要负责的是决定在当前时间步应该存储多少来自输入的信息到细胞状态中，（tanh函数用于创建一个新的候选值，表示将要存储的信息。）

遗忘门决定从细胞状态中删除多少信息，类似于输入门，他由一个sigmoid激活函数组成，用于0-1之间的值，以表示要保留多少细胞状态中的信息。

细胞状态是lstm的核心部分，主要负责存储和传递信息，细胞状态是由输入门，遗忘门和输出门的操作来更新的。输入门和遗忘门的操作可以添加或删除信息，以便在细胞状态中更新信息。

最后就是输出门了 输出门决定细胞状态这种的那些信息应该传递到隐藏状态以供后续的预测和处理，输出门由一个sigmoid激活函数和一个tanh激活函数组成，sigmoid函数由于生成0-1之间的值，以控制那些信息将流向隐藏状态，而tanh函数用于缩放细胞状态中的信息，以便输出到隐藏状态。

这四个门共同协作，使lstm能够维护和更新内部状态，以便更好地捕获和传递长序列中的信息。这使得lstm在处理具有长期依赖关系的序列数据时非常有用，例如自然语言处理任务，时间序列分析等。
```

##### 70.hmm和crf的区别和联系

```
答：hmm是生成式模型   crf是判别式模型 

hmm由两个主要组成部分构成，第一部分是隐藏状态序列，第二是观测序列，hmm可以解决语音识别，词性标注，生物信息学中的蛋白质结构预测 他的解码主要是找到给定观测序列的最可能的隐藏状态序列。

crf是一种概率图用来建模条件概率分布，CRF通常用于标记和序列标注任务，如自然语言处理中的命名实体识别、词性标注和分块，以及计算机视觉中的物体识别，主要的思想是最大化条件概率分布，考虑输入特征和输出标签之间的关系，crf通常使用条件对数似然函数进行训练，可以采用梯度下降等优化算法进行参数估计。

hmm通常是用来做生成形任务的，crf通常是用于判别形任务，其中目标是根据输入条件预测输出标签序列。
```

##### 71.transformer结构以及各层作用

```
答：transformer可以做机器翻译，文本摘要，它的框架是由encoder-decoder两部分组成。
encoder(6个Block):encoder输入，encoder的子层结构。
decoder(6个Block):decoder输入，decoder的子层结构。
encoder 输入包括：词嵌入+位置嵌入
encoder 子层结构包括：多头注意力机制，残差网络，层次归一化，前馈神经网络。

decoder 输入包括：词嵌入+位置嵌入
decoder 子层结构包括：mask多头注意力机制，残差网络，层次归一化，encoder-decoder交叉注意力机制，前馈神经网络。
decoder 输出：线性层+softmax(词表大小分类)

encoder多头注意力机制：指的是q=k=v 作用：让一个词在不同语义表达更加丰富，softmax(q*k/根号dk)*v
残差网络：防止梯度消失
层次归一化：在多个维度进行归一化可以让模型效果更好，批次归一化单独考虑一个维度归一化没有任何意义。
前馈神经网络：2层的网络（2层线性层 512-1024，1024-512）

decoder mask多头注意力机制：为什么用mask:训练的时候语料全给模型，测试的时候decoder是一个字一个字生成，当预测第N个字的时候，是看不到N+1之后的信息的，而训练的时候可以看到后面的词的信息，为了保持训练和预测方式一致，用mask形式来做。

encoder-decoder交叉注意力机制：Q！= K = V, Q是decoder提供的，K,V是encoder的输出
训练的时候，数据是一次性给到模型的，而预测只给encoder的数据，decoder数据是不给的。
decoder生成的时候是从start起始符号开始，当碰到end符号结束，从左到右一个字一个字生成。
```

##### 72.transformer的层归一化如何修改其中的两个参数来训练

```
答：结构：层归一化是一种用于稳定和加速训练的标准化技术，通常应用于每个层的输出。它具有两个主要参数：缩放因子和偏移

手动初始化，正则化 

手动初始化这两个参数，指定他们的初始值，然后在训练过程中通过梯度下降来更新它们。

正则化应用L1或者L2正则化来限制参数的范围，防止过度拟合。
```

##### 73.bert为什么擅长文本理解，GPT为什么擅长文本生成

```
答：因为bert支持双向上下文理解，训练过程允许模型从文本中学习双向上下文信息，在预训练过程中，bert观察到整个输入文本，并能够理解一个词汇项的上下文，因此能够更好地处理复杂的文本关系。

gpt是一个自回归语言模型，他是按照顺序生成文本，只能访问已经生成的文本的上下文，这种单向性质使得gpt非常擅长生成连贯的文本，比如自然语言生成，对话生成。

大白话：BERT之所以擅长文本理解，是因为它能够双向理解文本的上下文，而GPT之所以擅长文本生成，是因为它是一个自回归的语言模型，能够按顺序生成文本并维护连贯性。

## 
```

##### 74.flask或fastapi前端调用接口出现跨域情况如何解决，如何设置跨域访问权限

```
答：在Flask中设置CORS，添加一个cors库，添加cors（app）一行代码
```

##### 75.如何调用fastapi生成的测试文档

```
答：使用Swagger UI，在运行FastAPI应用程序的服务器上，打开浏览器，在浏览器中，访问FastAPI应用程序的根URL，在根URL后面追加`/docs`，以访问Swagger UI页面，显示FastAPI生成的Swagger UI文档，可以在这里查看API端点、请求示例和测试
```

##### 76.为什么ChatGPT回答错误后，经过提示可以回答正确

```
答：因为他训练的时候就没有学会这种方式，所以他匹配不到正确答案，如果给他提示正确的话，他学过这类的问法，他就可以通过这种问法学习，因为这种问法他学的比较好，所以正确问答就能回答出来。

因为他里面有一个有监督学习和强化学习，通过反复的修改，相当于给他拉入了一个学过的知识库中了，所以他可以正确。
```

##### 77.调用bert模型时如何从代码层面关掉训练过程

```
答：在调用BERT模型时，如果正在进行微调，可以通过在微调代码中冻结模型的权重来关闭训练过程或者不更新BERT的权重来关闭训练过程
```

##### 78.数字诊疗医生的输出是什么？

```
答：输出的是一个闲聊的东西，一个是诊断疾病的东西。
```

##### 79.数字诊疗医生这个项目中，知识图谱是什么地位？

```
答：知识库的输出：优先通过症状，在知识库里查找疾病，如果没有查找到疾病我们启动我们训练好的大语言模型进行问答，是我们微调过的大语言模型，他不仅支持闲聊也支持医疗问答。
```

##### 80.命名实体识别的输入是什么？

```
答：输入是每一个打好标签的字，输入是文档的形式，BIO标签，每一个字为一行，第一个是字加空格，第二个就是他的一个标注形式bioes
```

##### 81.命名实体审核和我们的这个项目整体存在什么关系？

```
答：命名实体审核在我们的项目中主要是用来审核实体的
```

##### 82.线上有这个语音诊断吗？

```
答：我们有人工语音诊断，我们诊断语音只有是人工，医生给他诊断。
```

##### 83.闲聊是怎么做的？

```
答：最开始我们因为语料不足把这一块交给别人做的，在回答的维度上有一定的迷幻性和不符合事实性，今年我们在这一块进行优化了，是我主要做的，使用的是大语言模型加微调。在微调的时候我们添加数据量对迷幻性和不符合事实性进行了优化，最后做出来的要比别人做的好。
```

##### 84.simcse+faiss是怎么做的？

```
答：SimCSE是一种自然语言处理中用于学习文本句子嵌入的对比学习方法，它使用相似性损失来鼓励模型在嵌入空间中将相似的句子靠近彼此。

Faiss是一种高性能的相似性搜索库，用于在大规模嵌入空间中进行相似性搜索最后我们结合SimCSE和Faiss的方法通常用于文本相似性搜索和相关应用中。

首先我们通过bert训练一个simcse模型将训练的句子嵌入到模型里，然后生成文本句子嵌入到训练好的simcse里，构建faiss索引将生成的文本句子嵌入到faiss库中，构建一个高效的相似性搜索索引，最后faiss会根据嵌入空间中的相似度，对给定的查询句子进行查询并返回与查询句子最相似的句子。
```

##### 85.语料是选训练语料还是评估语料？

```
答：我们语料有分层的，训练语料和评估语料我们都有，但是我们要保证评估语料没在训练语料中出现过，而且要保证预料的均衡，各种类别的都覆盖到。
```

##### 86.语料挑选有什么标准吗？

```
答：我们的标准是有id，问答，类别，标签。

一开始的数据噪音非常多，然后我们基于我们自己定义的规则进行的去除噪音，

基于规则的噪音过滤：
1、删除在对话中的平台标签
2、从网址字符串中删除文本
3、对话数超过30的会话拆分为多轮对话数少于30的会话
4、在一个句子中仅保留重复超过6次的短语或单词
5、如果回答太长或太短，则删除对话
6、如果识别为广告则移除对话
7、如果回复中90％的三元组是高频三元组，则删除对话
8、如果回复具有某些特定形式的通用回复，则删除对话
9、删除回复与帖子相同的对话
10、脏话，敏感词和方言
11、有专业术语
12、名称，称谓和未知缩写
13、特殊符号和表情符号
14、平台标志，例如与广告，图片和视频相关的单词
基于分类器的过滤：
15、回复不流畅或句子中有严重错别字
16、回复的信息不完整
17、对话的主题是有时效性的
18、帖子中未提及的节日，地点，性别和时间出现在回复中
19、帖子和回复无关
```

##### 87.你们的模型是做通用的还是只是医疗方面的？

```
答：这个项目中做的是医疗方面的，但是另一个项目中做的大模型是通用的。
```

##### 88.打分用到强化学习里面还是用来评估？

```
答：我们打分这个环节里面都用了，强化学习用到一个有监督的反馈学习，评估用来对每个维度打分，两个地方都有打分的环节，打分的意义不一样。
```

##### 89.gpt和glm的区别？

```
答：GPT是一种基于Transformer架构的预训练语言模型，GPT的核心原理是预训练和微调。模型首先通过大规模的无监督学习阶段，对大量文本数据进行预训练，从而学习自然语言的语法、语义和世界知识。然后，可以通过微调，将模型适应特定的自然语言处理任务，如文本生成、机器翻译、情感分析。

是由嵌入层，位置编码，多头自注意力层，残差连接和归一化，前馈神经网络层，堆叠的编码器层，输出嵌入层和softmax层构成的。

glm是一种统计模型，不同于gpt的是他不是一个神经网络模型，而是一种基于线性关系的模型，glm也是一种监督学习模型，用于建模和分析因变量与自变量之间的关系，可以处理分类和回归问题。

首先就是他们的应用领域不同，gpt是处理自然语言的模型，主要用于文本生成，文本理解和语言相关任务，glm用于建模和分析因变量与自变量之间的关系，glm广泛用于各种领域，有经济学，生活统计，医学和社会科学。

然后就是学习方法的不同，gpt使用的是深度学习方法，经过预训练和微调来适应特定的nlp任务的，glm是通过最大似然估计传统统计技术来估计参数的。
```

##### 90.大语言模型怎么做的？

```
答：
```

##### 91.你们在训练的时候从0到1训练的吗？为什么考虑重新训练？没有用模型原先的权重吗？

```
答：我们参考的chatglm-6b的模型参数，权重。
```

##### 92.用的是chatglm还是glm框架？

```
答：我们用的glm的框架
```

##### 93.用的多少数据量在4张A100上？

```
答：我们用的1张A100，还有8张4090可以用，总共350多个G
```

##### 94.你们用一千多万数据，是怎么做的chatglm-6b的模型？（无监督训练怎么做的）

```
答：我们直接把参数拿过来改参数进行训练的，然后再说一下无监督模型的训练
```

##### 95.数据是怎么构成的？

```
答：数据是通过开源的悟道数据和github上的开源数据，有维基百科，百科问答，社区问答，翻译语料，书生万卷拿来进行我们自己构建的一套规则清洗，清洗之后构成的。

基于规则的噪音过滤：
1、删除在对话中的平台标签
2、从网址字符串中删除文本
3、对话数超过30的会话拆分为多轮对话数少于30的会话
4、在一个句子中仅保留重复超过6次的短语或单词
5、如果回答太长或太短，则删除对话
6、如果识别为广告则移除对话
7、如果回复中90％的三元组是高频三元组，则删除对话
8、如果回复具有某些特定形式的通用回复，则删除对话
9、删除回复与帖子相同的对话
10、脏话，敏感词和方言
11、有专业术语
12、名称，称谓和未知缩写
13、特殊符号和表情符号
14、平台标志，例如与广告，图片和视频相关的单词
基于分类器的过滤：
15、回复不流畅或句子中有严重错别字
16、回复的信息不完整
17、对话的主题是有时效性的
18、帖子中未提及的节日，地点，性别和时间出现在回复中
19、帖子和回复无关
```

##### 96.训练的时候用的多大的batch，学习率是多少？

```
答：我们的batch是用的是64批次，学习率是e-5（0.00001）
```

##### 97.你们用过并行的技术了吗？有几种并行的方式？

```
答：我们用的是deepspeed他支持并行，Deepspeed是一个分布式训练框架，采用多种技术手段来加速训练，包括使用梯度累积来提高批量大小，从而提高训练效率。

还使用了ZeRO内存优化技术用于提高显存效率和计算效率。ZeRO可以克服数据并行和模型并行的局限性，同时实现两者的优点，使用动态通信调度来在分布式设备之间共享必要的状态，将模型状态和梯度进行分区以节省大量内存，还可以利用CPU和GPU内存来训练大型模型。

总之，deepspeed框架训练大模型可以减少训练内存占用、减少了分布式训练期间的通信量、支持长序列，可以快速收敛以加速训练提高效率。

它分为数据并行和模型并行，数据并行就是把等配的数据分配到不同的资源上，他的每一块代码分配到不同的GPU上进行运行，然后再把所有的合并到一起，要保证模型是可以拆分的。
```

##### 98.具体的微调方式是什么？

```
答:我们这里用的是LoRa，P-Tuning，但是我还知道其他的微调方法比如有Fine-Tuning，P-Tuning-V2，RLHF但是我们没有尝试

LoRa属于部分参数微调，它就是在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩，用随机高斯分布初始化 A，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵 B ，训练完成后，将 B 矩阵与 A 矩阵相乘后合并预训练模型参数作为微调后的模型参数，是当下最流行的微调方式

P-Tuning-V2他也属于部分参数微调，就是在每一层都加入了prompts tokens作为输入，训练的时候这部分参数用于chatglm微调
```

##### 99.LangChain-chatchat是产品还是做得一个demo？

```
答：是一个我们公司给自己做得一个产品，因为我们公司有很多的文献没有整理，不方便查找，所以我们公司就借助langchain做了一个自己的知识库，他可以帮助我们公司把公司拥有的文献全部存进去方便之后我们的使用。
```

##### 100.当时为什么选择NLP？

```
答：因为当时没有大语言模型，然后跟cv比起来，nlp的挑战难度比较大，就是当时觉得之后的机器人一问一答的技术有意思所以也是想挑战一下。
```

##### 101.介绍一下医疗百科助手？

```

```

##### 102.这个项目最终需求方的反应效果，准确率之类的？

```
答：首先我们的这个项目他是给医院做的，为了缓解医院的压力，使用百科问答机器人提前回答患者的各种问题，丰富医院的HIS库，我们的一个流程图就是，通过用户给的一个输入，进入我们定义的一个六意图的分类，去判断用户的这句话是我们定义的哪一类，如果我们判断的是接受的意图的话我们的助手会直接使用存储信息回复用户的，如果是诊断的意图的话我们又在诊断意图这块做了一个13分类意图识别模型，13分类意图的识别会返回用户的一个意图和置信度，然后接我们的判断置信度的一个规则，如果置信度小于0.4的话归入否定就是我们没有给模型训练到这方面的东西，所以我们会返回用一个模版回复说正在学习中，如果置信度在大于0.4且小于0.8的区间我们保持怀疑然后进入neo4j查询，如果查询到了就储存对话信息使用追问模版回复用户并且查询是不是有上一轮的一个存储信息如果有储存好的一个信息就直接返回，如果没有的话直接就是模版回复正在学习，如果置信度大于或者等于0.8就是一个相信的诊断，直接接入neo4j数据库进行查询，如果查询到就模版回复加查询到的信息返回给用户，如果没有查询到，还是回复一个模版回复然后储存用户的信息进行后续的一个学习并返回给用户一个正在学习中的模版回复。
步骤2 简介项目框架：
步骤3 遇到的问题
这个是坑点：我们的一开始的项目一个批次的准确率在50~60的一个区间，后来经过一些处理比对发现是我们的数据出现了问题一开始以为是我们的数据没有清洗干净，但是又进行清洗之后发现不是数据的问题，然后我们就调转处理的方向从添加数据进行，后续我们又清洗了20w医疗语料还有15%的闲聊语料，添加进去之后准确率就保持在95%左右了，里面还有一些纬度没有完全清洗掉，在迷幻性和是否符合事实这俩纬度上还存在一些问题，调研论文之后还是没有一些特别好的方法，采用的是模版匹配+tinnybert+rnn的一个模型，最后的准确率在95%左右了，初始损失在2.84左右训练完之后的损失在0.92-0.96左右的一个区间。

我们的分类模型准确率在92%以上   f1的准确率在94以上   实体识别的准确率在95以上 
```

##### 103.医疗百科助手数据怎么获取的？

```
答：我们的数据有公司自己的数据也有合作方提供的数据，还有我们爬取39健康网和寻医问药网的数据。入库的实体使我们经过逐条审核的。
```

##### 104.知识图谱部署以后，实际效果怎么样？

```

```

##### 105.

```

```

##### 106.

```

```

##### 107.

```

```

##### 108.

```

```

##### 109.

```

```

##### 110.

```

```



1.做个自我介绍？
2.大语言模型的微调分为哪几个步骤？每个步骤都采用什么样的任务对他进行的训练？

```

```

3.模型的输入输出都是什么？

```
答：如果是微调的那输入就是一个问题一个答案，问答对的形式，输出是你给他个提示他给你生成的一句话
```

4.预训练的输入输出？大模型输入输出？

```
输入是无监督语料一行是一句话，输出是生成的一句话。 大语言模型
```

5.每个步骤都是做什么任务的？

```
步骤
```

6.有生成能力了 如何把他训练成有对话的模型？

```
进行一个微调，数据就是问答形式
```

7.如何把其他的自然语言任务转化成问答任务呢？

```
设置一个模板让模型去学习，
```

8.现在有生成模型接收一串id输出的下一个词的概率分布 如何实现极速搜索 并输出分值最高的一句话？

```

```

9.transformer的自注意力机制的自是什么？

```
q=k=v,文本中每个字与每个字内部进行一个计算
```

10.mask注意力机制的生成过程？

```
decoder中mask注意力机制，从左到右计算
```

11.输入输出都是文本怎么用chatglm框架组装训练用的输入和输出？

```

```

12.已有的数据集怎么构造模型的输入输出？

```

```

13.你用过什么高效微调的方法？

```
LoRa属于部分参数微调，它就是在原始预训练语言模型旁边增加一个旁路，做降维再升维的操作来模拟内在秩，用随机高斯分布初始化 A，用零矩阵初始化B，训练时固定预训练模型的参数，只训练矩阵 A 与矩阵 B ，训练完成后，将 B 矩阵与 A 矩阵相乘后合并预训练模型参数作为微调后的模型参数，是当下最流行的微调方式
```

14.简说一下transformer或者gpt里的注意力层输入到输出的运算？

```
softmax(q*k/gen'hao)
```

15.mask如果我要屏蔽一个位置应该用什么值？

```

```

16.自注意力机制与原版的gpt有什么不一样

```

```

17.KV缓存是怎么回事？

```

```

18.你有没有了解过其他的注意力的改进？

```

```

19.原版的decoder怎么同时处理的两个序列

```

```

20.模型炼化和非对称炼化？比如fp16

```

```



## 九.向面试官提问：

```
面试技巧：不好意思没有听清楚可以再说一次吗，给我十秒种时间我整理一下思路，面试官我这次面试可能紧张了没回答好，但有些问题我确实不太清楚该如何解决，可以帮我解答一下吗，

技术面试官问：你还有什么想问的吗？ 面试的最后一个问题
1：公司项目进展到什么地步了？已经上线了还是刚立项了没开始呢？------ 上线：进行优化    立项还没做：你要干的事很多
2：公司这边主要做什么项目？如果我有幸进公司需要我帮公司解决什么难题？----套出来你要做事，提前准备
3：项目组人员配置什么样的？----- 1：项目组刚成立 算你3个人（你进公司啥都要干）   2：项目组：算法这个几个人
4：项目持续稳定吗？回款稳定吗？我想找一个比较稳定的公司
5：你们项目这块数据量有多少，充足吗？追问大概有多少量？
6：这轮面试我过了吗？追问：一般多久出结果反馈给我？
面试官我没什么问题了，谢谢你！

HR: 
1 为什么离职？
2 薪资构成？ 年终多少薪资？
薪资构成： 底薪+绩效 举例：16000 底薪1万+绩效6000，我们每个月只要不出大状况 绩效都能拿到系数1 ，我们还有项目奖金 一般是3月1发 最晚半年，看项目汇款速度!   12-13薪资
3 你多久能入职？拿到offer后 1周内入职
4 你现在住哪？人在北京，杭州那边问 你现在在哪？  我人在北京 一周去杭州那边！
5 你觉得你有什么缺点？平时工作做完一个任务，没有及时整理归纳，导致后面的任务技术复用的时候，还得从新写，比较麻烦，所以以后要及时整理，做个查找的脑图之类的，提高工作效率！
6 你能来公司来面试吗?我目前在北京，杭州估计要哪号去，17号去贵公司面试可以吗？
7 第一轮面试完事？
HR  我面试结果出来了吗？  1 告诉你结果    2 不说话 （第二天 再问下，如果还不说话，不搭理他了）
8 你是统招本科学历吗？别编：实话实话
9 你是本科学历吗？我是本科学历
10 你能接受加班吗？你对加班怎么看？我以前基本上每天9点以后下班！就没有不加班过！
11 你什么时间方便面试？明天下午2点 上午10点 方便面试吗？下午2点 下午4面试，明天都可以，要不明天上午10点你看可以吗？
```
